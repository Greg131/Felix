{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering evaluation\n",
    "Script to evaluate clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "#from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.preprocessing import LabelBinarizer\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.feature_selection import RFECV, RFE, SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_project = Path.home() / Path('Google Drive/Felix')\n",
    "path_data = path_project / Path(\"data\")\n",
    "path_dump = path_project / Path(\"dump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "file = path_data / Path(\"dataset.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    dataset = pd.read_csv(fp,  encoding='utf-8',low_memory=False, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load feature sets\n",
    "filename = path_dump / Path(\"dict_features_sets.sav\")\n",
    "with open(filename, 'rb') as fp:\n",
    "     dict_features_sets = pickle.load(fp)\n",
    "\n",
    "usual_common_features = dict_features_sets['usual_common_features']\n",
    "indiv_act_features = dict_features_sets['indiv_act_features']\n",
    "indiv_semi_act_features = dict_features_sets['indiv_semi_act_features']\n",
    "RFE_LogisticRegression_20_features = dict_features_sets['RFE_LogisticRegression_20_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading clustering\n",
    "file = path_data / Path(\"clustTest1.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    clustTest1 = pd.read_csv(fp,  encoding='utf-8',low_memory=False, sep=\";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number exemple: 10674\n",
      "- training set: 160\n",
      "- test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n"
     ]
    }
   ],
   "source": [
    "df = dataset.loc[:,:]\n",
    "# reducing problem to a 2 class classification problem\n",
    "df[\"HEUREUX_CLF\"] = 0\n",
    "df.loc[df[\"HEUREUX\"]==4, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==3, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==5, \"HEUREUX_CLF\"] = None\n",
    "\n",
    "scope = ( RFE_LogisticRegression_20_features | indiv_act_features )  & set(dataset.columns)\n",
    "n_max = 2000\n",
    "\n",
    "df = df.loc[:,scope | {\"HEUREUX_CLF\"} ].dropna()\n",
    "features = df.loc[:,scope ].columns\n",
    "\n",
    "X = df.loc[:,scope]\n",
    "y = df[\"HEUREUX_CLF\"]\n",
    "\n",
    "\n",
    "Xs, ys = resample(X, y, random_state=42)\n",
    "\n",
    "Xs = Xs.iloc[0:n_max,:]\n",
    "ys = ys.iloc[0:n_max]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Number exemple: {y.shape[0]}\\n- training set: \\\n",
    "{y_train.shape[0]}\\n- test set: {y_test.shape[0]}\")\n",
    "print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "print(f\"Number of class: {len(np.unique(y))}\")\n",
    "for c in np.unique(y):\n",
    "    print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determination of optimal hyperparameters in 36.6 s\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 32} \n",
      "Accuracy Score of cross valdation 71.88%\n",
      "Random Forest, p=66\n",
      "Model score\n",
      "- Accuracy : 62.5 %\n",
      "- Precision : 76.9 % (Happy # positive class)\n",
      "- Recall : 69.0 %\n",
      "- F1 score : 72.7 %\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "n_estimators_range = [32,64,128,256,512]\n",
    "max_depth_range = [4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32,\n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced'}\n",
    "clf = RandomForestClassifier(**params)\n",
    "\n",
    "grid = GridSearchCV(clf, scoring='accuracy', param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Determination of optimal hyperparameters in {time.time() - startTime:0.1f} s\")\n",
    "print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "Accuracy Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "\n",
    "# Learning on full training set with optimals hyperparameters and score on test set\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "          'n_estimators' : grid.best_params_['n_estimators'],\n",
    "          'max_depth' : grid.best_params_['max_depth']}\n",
    "clf = RandomForestClassifier(**params).fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"Random Forest, p={X_train.shape[1]}\")\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")\n",
    "res_full  = {\n",
    "    'f1_score' : f1,\n",
    "    'accuracy' : accuracy,\n",
    "    'precision' : p,\n",
    "    'recall' : r\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation on each clusters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators_range = [16,32,64,128]\n",
    "max_depth_range = [2,4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "params = {'max_features' :'sqrt', \n",
    "          'random_state' : 32, \n",
    "          'min_samples_split' : 2, \n",
    "          'class_weight' : 'balanced'\n",
    "         }\n",
    "scope = ( RFE_LogisticRegression_20_features | indiv_act_features )  & set(dataset.columns)\n",
    "features = df.loc[:,scope].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust1\n",
      "liste of clusters : [1 2 3 4 5 6]\n",
      "++++++++++++\n",
      "cluster 1 : 295 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 32} \n",
      "        Score of cross valdation 76.88%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 1729 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 128} \n",
      "        Score of cross valdation 71.25%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 3633 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 16} \n",
      "        Score of cross valdation 81.25%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 218 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 16} \n",
      "        Score of cross valdation 88.12%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 137 elements\n",
      "Number exemple: 102\n",
      "        - training set: 81\n",
      "        - test set: 21\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 64} \n",
      "        Score of cross valdation 85.19%\n",
      "\n",
      "++++++++++++\n",
      "cluster 6 : 24 elements\n",
      "Number exemple: 20\n",
      "        - training set: 16\n",
      "        - test set: 4\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 2, 'n_estimators': 64} \n",
      "        Score of cross valdation 62.50%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust2\n",
      "liste of clusters : [4 6 5 1 3 2 7]\n",
      "++++++++++++\n",
      "cluster 4 : 212 elements\n",
      "Number exemple: 194\n",
      "        - training set: 155\n",
      "        - test set: 39\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 128} \n",
      "        Score of cross valdation 83.87%\n",
      "\n",
      "++++++++++++\n",
      "cluster 6 : 1137 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "        Score of cross valdation 78.12%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 750 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 32} \n",
      "        Score of cross valdation 77.50%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 1257 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 16} \n",
      "        Score of cross valdation 68.12%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 1254 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 128} \n",
      "        Score of cross valdation 71.88%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 857 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "        Score of cross valdation 80.00%\n",
      "\n",
      "++++++++++++\n",
      "cluster 7 : 569 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 16} \n",
      "        Score of cross valdation 74.38%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust3\n",
      "liste of clusters : [5 4 1 2 3]\n",
      "++++++++++++\n",
      "cluster 5 : 373 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "        Score of cross valdation 67.50%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 2682 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 2, 'n_estimators': 32} \n",
      "        Score of cross valdation 72.50%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 1593 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 64} \n",
      "        Score of cross valdation 75.62%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 1246 elements\n",
      "Number exemple: 200\n",
      "        - training set: 160\n",
      "        - test set: 40\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 32} \n",
      "        Score of cross valdation 76.25%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 142 elements\n",
      "Number exemple: 105\n",
      "        - training set: 84\n",
      "        - test set: 21\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 32} \n",
      "        Score of cross valdation 80.95%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_clustering_methods = []\n",
    "clustering_methods = clustTest1.columns[0:3]\n",
    "\n",
    "for method in clustering_methods:\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"\\nAnalysis cluster method {method}\")\n",
    "    cluster_list = clustTest1[method].unique()\n",
    "    print(f\"liste of clusters : {cluster_list}\")\n",
    "    score_cluster = []\n",
    "    for cluster in cluster_list:\n",
    "        index_scope = clustTest1.loc[clustTest1[method]==cluster,:].index\n",
    "        print(\"++++++++++++\")\n",
    "        print(f\"cluster {cluster} : {len(index_scope)} elements\")\n",
    "        \n",
    "        Xc = X.loc[index_scope.intersection(X.index),:]\n",
    "        yc = y[index_scope.intersection(X.index)]\n",
    "        \n",
    "        Xs, ys = resample(Xc, yc, random_state=42)\n",
    "        \n",
    "        Xs = Xs.iloc[0:n_max,:]\n",
    "        ys = ys.iloc[0:n_max]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(Xs, ys,\n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=42)\n",
    "\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "                \n",
    "        print(f\"Number exemple: {ys.shape[0]}\\n\\\n",
    "        - training set: {y_train.shape[0]}\\n\\\n",
    "        - test set: {y_test.shape[0]}\")\n",
    "        print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "        print(f\"Number of class: {len(np.unique(y))}\")\n",
    "        for c in np.unique(y):\n",
    "            print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")\n",
    "            \n",
    "            \n",
    "        startTime = time.time()\n",
    "        clf = RandomForestClassifier(**params)\n",
    "        grid = GridSearchCV(clf, \n",
    "                            scoring='accuracy', \n",
    "                            param_grid=param_grid)\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "        Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "        print()\n",
    "\n",
    "        # Learning on full training set with optimals hyperparameters and score on test set\n",
    "        params_opt = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "                      'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "                      'n_estimators' : grid.best_params_['n_estimators'],\n",
    "                      'max_depth' : grid.best_params_['max_depth']}\n",
    "        clf = RandomForestClassifier(**params_opt).fit(X_train, y_train)\n",
    "\n",
    "            \n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        f1 = f1_score(y_test, y_test_pred)\n",
    "        p = precision_score(y_test, y_test_pred)\n",
    "        r = recall_score(y_test, y_test_pred)            \n",
    "\n",
    "        res  = {'f1_score' : f1,\n",
    "                'accuracy' : accuracy,\n",
    "                'precision' : p,\n",
    "                'recall' : r}\n",
    "            \n",
    "        cl = {'cluster' : cluster,\n",
    "              'size' : len(index_scope),\n",
    "              'model' : 'RandomForestClassifier',\n",
    "              'params' : params_opt,\n",
    "              'metrics' : res\n",
    "             }\n",
    "         \n",
    "        score_cluster.append(cl)\n",
    "        \n",
    "    d = {'clustering_method' : method,\n",
    "         'cluster_scores' : score_cluster\n",
    "        }\n",
    "    score_clustering_methods.append(d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method clust1:\n",
      "cluster 1 (295), f1 macro 81.0%\n",
      "cluster 2 (1729), f1 macro 81.5%\n",
      "cluster 3 (3633), f1 macro 76.4%\n",
      "cluster 4 (218), f1 macro 84.6%\n",
      "cluster 5 (137), f1 macro 54.5%\n",
      "cluster 6 (24), f1 macro 80.0%\n",
      "average f1 on clusters 77.9% gain 5.1\n",
      "\n",
      "method clust2:\n",
      "cluster 4 (212), f1 macro 87.8%\n",
      "cluster 6 (1137), f1 macro 89.2%\n",
      "cluster 5 (750), f1 macro 87.9%\n",
      "cluster 1 (1257), f1 macro 57.8%\n",
      "cluster 3 (1254), f1 macro 73.9%\n",
      "cluster 2 (857), f1 macro 84.2%\n",
      "cluster 7 (569), f1 macro 68.3%\n",
      "average f1 on clusters 76.6% gain 3.9\n",
      "\n",
      "method clust3:\n",
      "cluster 5 (373), f1 macro 73.7%\n",
      "cluster 4 (2682), f1 macro 70.6%\n",
      "cluster 1 (1593), f1 macro 89.6%\n",
      "cluster 2 (1246), f1 macro 75.5%\n",
      "cluster 3 (142), f1 macro 91.7%\n",
      "average f1 on clusters 77.3% gain 4.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    total_size = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']} ({score_cluster['size']}), f1 macro {100*score_cluster['metrics']['f1_score']:0.1f}%\")  \n",
    "        average_score += score_cluster['metrics']['f1_score']*score_cluster['size']\n",
    "        total_size += score_cluster['size']\n",
    "        \n",
    "    average_score = average_score / total_size\n",
    "    print(f\"average f1 on clusters {100*average_score:0.1f}% gain {100*(average_score-res_full['f1_score']):0.1f}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method clust1:\n",
      "cluster 1 (295) , accuracy 80.0%\n",
      "cluster 2 (1729) , accuracy 75.0%\n",
      "cluster 3 (3633) , accuracy 67.5%\n",
      "cluster 4 (218) , accuracy 80.0%\n",
      "cluster 5 (137) , accuracy 52.4%\n",
      "cluster 6 (24) , accuracy 75.0%\n",
      "average accuracy on clusters 70.4% gain 7.9\n",
      "\n",
      "method clust2:\n",
      "cluster 4 (212) , accuracy 87.2%\n",
      "cluster 6 (1137) , accuracy 82.5%\n",
      "cluster 5 (750) , accuracy 80.0%\n",
      "cluster 1 (1257) , accuracy 52.5%\n",
      "cluster 3 (1254) , accuracy 70.0%\n",
      "cluster 2 (857) , accuracy 77.5%\n",
      "cluster 7 (569) , accuracy 67.5%\n",
      "average accuracy on clusters 71.4% gain 8.9\n",
      "\n",
      "method clust3:\n",
      "cluster 5 (373) , accuracy 75.0%\n",
      "cluster 4 (2682) , accuracy 62.5%\n",
      "cluster 1 (1593) , accuracy 82.5%\n",
      "cluster 2 (1246) , accuracy 67.5%\n",
      "cluster 3 (142) , accuracy 90.5%\n",
      "average accuracy on clusters 70.2% gain 7.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    total_size = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']} ({score_cluster['size']}) , accuracy {100*score_cluster['metrics']['accuracy']:0.1f}%\")  \n",
    "        average_score = average_score + score_cluster['metrics']['accuracy']*score_cluster['size']\n",
    "        total_size += score_cluster['size']\n",
    "    average_score = average_score / total_size\n",
    "    print(f\"average accuracy on clusters {100*average_score:0.1f}% gain {100*(average_score-res_full['accuracy']):0.1f}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
