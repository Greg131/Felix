{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#%pylab inline\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_selection import RFECV, RFE, SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_project = Path.home() / Path('Google Drive/Felix')\n",
    "path_data = path_project / Path(\"data\")\n",
    "path_dump = path_project / Path(\"dump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "file = path_data / Path(\"dataset.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    dataset = pd.read_csv(fp,  encoding='utf-8',low_memory=False, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load feature sets\n",
    "filename = path_dump / Path(\"dict_features_sets.sav\")\n",
    "with open(filename, 'rb') as fp:\n",
    "     dict_features_sets = pickle.load(fp)\n",
    "\n",
    "usual_common_features = dict_features_sets['usual_common_features']\n",
    "indiv_act_features = dict_features_sets['indiv_act_features']\n",
    "indiv_semi_act_features = dict_features_sets['indiv_semi_act_features']\n",
    "RFE_LogisticRegression_20_features = dict_features_sets['RFE_LogisticRegression_20_features']\n",
    "#lasso_20_features = dict_features_sets['lasso_20_features']\n",
    "#lasso_50_features = dict_features_sets['lasso_50_features']\n",
    "#lasso_100_features = dict_features_sets['lasso_100_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.loc[:,:]\n",
    "# reducing problem to a 2 class classification problem\n",
    "df[\"HEUREUX_CLF\"] = 0\n",
    "df.loc[df[\"HEUREUX\"]==4, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==3, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==5, \"HEUREUX_CLF\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number exemple: 2000\n",
      "- training set: 1600\n",
      "- test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.6%\n",
      "class 1 : 64.4%\n"
     ]
    }
   ],
   "source": [
    "scope = RFE_LogisticRegression_20_features | indiv_act_features\n",
    "\n",
    "n_max = 2000\n",
    "df = df.loc[:,scope | {\"HEUREUX_CLF\"} ].dropna()\n",
    "features = df.loc[:,scope ].columns\n",
    "\n",
    "X = df.loc[:,scope]\n",
    "y = df[\"HEUREUX_CLF\"]\n",
    "\n",
    "X, y = resample(X, y, random_state=42)\n",
    "\n",
    "X = X.iloc[0:n_max,:]\n",
    "y = y.iloc[0:n_max]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Number exemple: {y.shape[0]}\\n- training set: \\\n",
    "{y_train.shape[0]}\\n- test set: {y_test.shape[0]}\")\n",
    "print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "print(f\"Number of class: {len(np.unique(y))}\")\n",
    "for c in np.unique(y):\n",
    "    print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEqCAYAAAACibeEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10555ed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Détermination des paramètres optimaux en 11.5 s\n",
      "Pénalisation l1, valeur optimale : C = 0.07\n",
      "Pénalisation l2, valeur optimale : C = 0.03\n"
     ]
    }
   ],
   "source": [
    "nb_value = 50 # Nombre de valeurs testées pour l'hyperparamètre\n",
    "mean_score_l1 = np.zeros(nb_value)\n",
    "mean_score_l2 = np.zeros(nb_value)\n",
    "C_log = np.logspace(-2.5,1,nb_value)\n",
    "cv = 6 # V-fold, nombre de fold\n",
    "\n",
    "mean_score_l1 = np.empty(nb_value)\n",
    "std_scores_l1 = np.empty(nb_value)\n",
    "\n",
    "mean_score_l2 = np.empty(nb_value)\n",
    "std_scores_l2 = np.empty(nb_value)\n",
    "\n",
    "np.random.seed(seed=42) \n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "for i, C in enumerate(C_log):\n",
    "    clf = LogisticRegression(C=C, penalty='l1', \n",
    "                             tol=0.01, random_state=42, \n",
    "                             class_weight='balanced')\n",
    "    mean_score_l1[i] = 100*np.mean(1-cross_val_score(clf, \n",
    "                                                     X_train, \n",
    "                                                     y_train,\n",
    "                                                     cv=cv, \n",
    "                                                     scoring='accuracy'))\n",
    "    std_scores_l1[i] = 100*np.std(1-cross_val_score(clf, \n",
    "                                                    X_train, \n",
    "                                                    y_train, \n",
    "                                                    cv=cv, \n",
    "                                                    scoring='accuracy'))    \n",
    "\n",
    "\n",
    "for i, C in enumerate(C_log):\n",
    "    clf = LogisticRegression(C=C, penalty='l2', tol=0.01, random_state=42, class_weight='balanced')\n",
    "    mean_score_l2[i] = 100*np.mean(1-cross_val_score(clf, \n",
    "                                                     X_train, \n",
    "                                                     y_train, \n",
    "                                                     cv=cv, \n",
    "                                                     scoring='accuracy'))\n",
    "    std_scores_l2[i] = 100*np.std(1-cross_val_score(clf, \n",
    "                                                    X_train, \n",
    "                                                    y_train, \n",
    "                                                    cv=cv, \n",
    "                                                    scoring='accuracy'))    \n",
    "    \n",
    "plt.figure()\n",
    "plt.semilogx(C_log,mean_score_l1[:],'r',linewidth=2,label='moyenne (l1)')\n",
    "plt.semilogx(C_log,mean_score_l1[:]-0.5*std_scores_l1[:],\n",
    "             'r--', label=u'+/-0.5 écart type')\n",
    "plt.semilogx(C_log,mean_score_l1[:]+0.5*std_scores_l1[:],'r--')\n",
    "\n",
    "plt.semilogx(C_log,mean_score_l2[:],'g',linewidth=2,label='moyenne (l2)')\n",
    "plt.semilogx(C_log,mean_score_l2[:]-0.5*std_scores_l2[:], 'g--', label=u'+/-0.5 écart type')\n",
    "plt.semilogx(C_log,mean_score_l2[:]+0.5*std_scores_l2[:],'g--')\n",
    "\n",
    "plt.xlabel(\"Valeur de pénalisation C = 1/lambda\")\n",
    "plt.ylabel(u\"Erreur de validation croisée (%)\\n(Taux moyen d'erreur de classification)\")\n",
    "plt.title(u\"Choix de l'hyperparamètre C\\npar validation croisée \\\n",
    "(V-fold avec V = %s)\" % (cv)) \n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(\"Détermination des paramètres optimaux en %0.1f s\" % (time.time() - startTime))\n",
    "print(\"Pénalisation l1, valeur optimale : C = %0.2f\" % (C_log[np.argmin(mean_score_l1)]))\n",
    "print(\"Pénalisation l2, valeur optimale : C = %0.2f\" % (C_log[np.argmin(mean_score_l2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score\n",
      "- Accuracy : 70.8 %\n",
      "- Precision : 81.5 % (Happy # positive class)\n",
      "- Recall : 71.2 %\n",
      "- F1 score : 76.0 %\n"
     ]
    }
   ],
   "source": [
    "# Learning on full training set with optimals hyperparameters \n",
    "# and score evaluation on test set\n",
    "clf = LogisticRegression(C=C_log[np.argmin(mean_score_l1)], \n",
    "                         penalty='l1', \n",
    "                         random_state=42, \n",
    "                         class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score\n",
      "- Accuracy : 70.0 %\n",
      "- Precision : 81.2 % (Happy # positive class)\n",
      "- Recall : 70.0 %\n",
      "- F1 score : 75.2 %\n"
     ]
    }
   ],
   "source": [
    "# Learning on full training set with optimals hyperparameters \n",
    "# and score evaluation on test set\n",
    "clf = LogisticRegression(C=C_log[np.argmin(mean_score_l2)], \n",
    "                         penalty='l2', \n",
    "                         random_state=42, \n",
    "                         class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAGqCAYAAABUEANoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNNaCIAiCIAgmmGisBUEQBEEQTDD/HxUmz1wvLJ/GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a12ba0ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#features = df_tmp.columns.drop([\"HEUREUX_CLF\"])\n",
    "# Use regression coefficients to rank features\n",
    "clf = LogisticRegression(C=C_log[np.argmin(mean_score_l2)], \n",
    "                         penalty='l2', \n",
    "                         random_state=42, \n",
    "                         class_weight='balanced')\n",
    "\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "coef_l2 = abs(clf.coef_)\n",
    "coef_sorted_l2 = -np.sort(-coef_l2).reshape(-1)\n",
    "features_sorded_l2 = np.argsort(-coef_l2).reshape(-1)\n",
    "features_name = np.array(features)\n",
    "features_name_sorted_l2 = features_name[features_sorded_l2]\n",
    "    \n",
    "clf = LogisticRegression(C=C_log[np.argmin(mean_score_l1)], \n",
    "                         penalty='l2', \n",
    "                         random_state=42, \n",
    "                         class_weight='balanced')\n",
    "    \n",
    "clf.fit(X_train,y_train)\n",
    "coef_l1 = abs(clf.coef_)\n",
    "coef_sorted_l1 = -np.sort(-coef_l1).reshape(-1)\n",
    "features_sorded_l1 = np.argsort(-coef_l1).reshape(-1)\n",
    "features_name_sorted_l1 = features_name[features_sorded_l1]\n",
    "\n",
    "nf = min(X_train.shape[1],20)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "ind = np.arange(nf)    # the x locations for the groups\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "p1 = plt.bar(ind, coef_sorted_l2[0:nf], 1, color='b',alpha=0.5)\n",
    "plt.ylabel('Feature importance')\n",
    "plt.title(u'Top %i features\\nLogistic regression pénalisation l2 C = 0.4' % nf)\n",
    "plt.xticks(ind + 0.35/2.0, features_name_sorted_l2[0:nf], rotation = 90)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "p1 = plt.bar(ind, coef_sorted_l1[0:nf], 1, color='b',alpha=0.5)\n",
    "plt.ylabel('Feature importance')\n",
    "plt.title(u'Top %i features\\nLogistic regression pénalisation l1 C = 7.2' % nf)\n",
    "plt.xticks(ind + 0.35/2.0, features_name_sorted_l1[0:nf], rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acionate NOT_AMIS, 0.2452\n",
      "acionate ASSOPOLI_[Nsp], 0.2107\n",
      "acionate VACANCES_Oui, 0.1913\n",
      "acionate NOT_LIBR, 0.1386\n",
      "acionate ASSOHUMA_[Nsp], 0.1125\n",
      "acionate ASSOCONF_Oui, 0.1022\n",
      "acionate NOT_FAMI, 0.0983\n",
      "acionate ASSOCONS_Oui, 0.0967\n",
      "acionate ASSOENVI_[Nsp], 0.0950\n"
     ]
    }
   ],
   "source": [
    "for i,feature in enumerate(features_name_sorted_l1):\n",
    "    if i < 20:\n",
    "        if feature in indiv_act_features:\n",
    "            print(f\"acionate {feature}, {coef_l1[abs(coef_l1) == coef_sorted_l1[i]][0]:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE ...on scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "scoring='accuracy' \n",
    "step = 0.05\n",
    "\n",
    "clf = LogisticRegression(C=1, \n",
    "                         penalty='l1', \n",
    "                         class_weight='balanced',\n",
    "                         random_state=42)\n",
    "\n",
    "rfecv = RFECV(estimator=clf, step=step, cv=StratifiedKFold(4),\n",
    "              scoring=scoring)\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(f\"Number of recurcive steps of {100*step:0.0f}% through {X_train.shape[1]} variables\")\n",
    "plt.ylabel(f\"Cross validation score \\n({scoring})\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "print(f\"Détermination des features optimales en %0.1f s\" % (time.time() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = rfecv.support_.copy()\n",
    "X_train = X_train[:,mask]\n",
    "X_test = X_test[:,mask]\n",
    "print(f\"Number of features: p={X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_value = 50 # Nombre de valeurs testées pour l'hyperparamètre\n",
    "mean_score_l1 = np.zeros(nb_value)\n",
    "mean_score_l2 = np.zeros(nb_value)\n",
    "C_log = np.logspace(-2.5,1,nb_value)\n",
    "cv = 6 # V-fold, nombre de fold\n",
    "\n",
    "mean_score_l1 = np.empty(nb_value)\n",
    "std_scores_l1 = np.empty(nb_value)\n",
    "\n",
    "mean_score_l2 = np.empty(nb_value)\n",
    "std_scores_l2 = np.empty(nb_value)\n",
    "\n",
    "np.random.seed(seed=42) \n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "for i, C in enumerate(C_log):\n",
    "    clf = LogisticRegression(C=C, penalty='l1', \n",
    "                             tol=0.01, random_state=42, \n",
    "                             class_weight='balanced')\n",
    "    mean_score_l1[i] = 100*np.mean(1-cross_val_score(clf, \n",
    "                                                     X_train, \n",
    "                                                     y_train,\n",
    "                                                     cv=cv, \n",
    "                                                     scoring='accuracy'))\n",
    "    std_scores_l1[i] = 100*np.std(1-cross_val_score(clf, \n",
    "                                                    X_train, \n",
    "                                                    y_train, \n",
    "                                                    cv=cv, \n",
    "                                                    scoring='accuracy'))    \n",
    "\n",
    "\n",
    "for i, C in enumerate(C_log):\n",
    "    clf = LogisticRegression(C=C, penalty='l2', tol=0.01, random_state=42, class_weight='balanced')\n",
    "    mean_score_l2[i] = 100*np.mean(1-cross_val_score(clf, \n",
    "                                                     X_train, \n",
    "                                                     y_train, \n",
    "                                                     cv=cv, \n",
    "                                                     scoring='accuracy'))\n",
    "    std_scores_l2[i] = 100*np.std(1-cross_val_score(clf, \n",
    "                                                    X_train, \n",
    "                                                    y_train, \n",
    "                                                    cv=cv, \n",
    "                                                    scoring='accuracy'))    \n",
    "    \n",
    "plt.figure()\n",
    "plt.semilogx(C_log,mean_score_l1[:],'r',linewidth=2,label='moyenne (l1)')\n",
    "plt.semilogx(C_log,mean_score_l1[:]-0.5*std_scores_l1[:],\n",
    "             'r--', label=u'+/-0.5 écart type')\n",
    "plt.semilogx(C_log,mean_score_l1[:]+0.5*std_scores_l1[:],'r--')\n",
    "\n",
    "plt.semilogx(C_log,mean_score_l2[:],'g',linewidth=2,label='moyenne (l2)')\n",
    "plt.semilogx(C_log,mean_score_l2[:]-0.5*std_scores_l2[:], 'g--', label=u'+/-0.5 écart type')\n",
    "plt.semilogx(C_log,mean_score_l2[:]+0.5*std_scores_l2[:],'g--')\n",
    "\n",
    "plt.xlabel(\"Valeur de pénalisation C = 1/lambda\")\n",
    "plt.ylabel(u\"Erreur de validation croisée (%)\\n(Taux moyen d'erreur de classification)\")\n",
    "plt.title(u\"Choix de l'hyperparamètre C\\npar validation croisée \\\n",
    "(V-fold avec V = %s)\" % (cv)) \n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(\"Détermination des paramètres optimaux en %0.1f s\" % (time.time() - startTime))\n",
    "print(\"Pénalisation l1, valeur optimale : C = %0.2f\" % (C_log[np.argmin(mean_score_l1)]))\n",
    "print(\"Pénalisation l2, valeur optimale : C = %0.2f\" % (C_log[np.argmin(mean_score_l2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning on full training set with optimals hyperparameters \n",
    "# and score evaluation on test set\n",
    "clf = LogisticRegression(C=C_log[np.argmin(mean_score_l1)], \n",
    "                         penalty='l1', \n",
    "                         random_state=42, \n",
    "                         class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning on full training set with optimals hyperparameters \n",
    "# and score evaluation on test set\n",
    "clf = LogisticRegression(C=C_log[np.argmin(mean_score_l2)], \n",
    "                         penalty='l2', \n",
    "                         random_state=42, \n",
    "                         class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model valuation on whole scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number exemple: 2000\n",
      "- training set: 1600\n",
      "- test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.6%\n",
      "class 1 : 64.4%\n"
     ]
    }
   ],
   "source": [
    "df = dataset.loc[:,:]\n",
    "# reducing problem to a 2 class classification problem\n",
    "df[\"HEUREUX_CLF\"] = 0\n",
    "df.loc[df[\"HEUREUX\"]==4, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==3, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==5, \"HEUREUX_CLF\"] = None\n",
    "\n",
    "scope = RFE_LogisticRegression_20_features | indiv_act_features\n",
    "\n",
    "n_max = 2000\n",
    "df = df.loc[:,scope | {\"HEUREUX_CLF\"} ].dropna()\n",
    "features = df.loc[:,scope ].columns\n",
    "\n",
    "X = df.loc[:,scope]\n",
    "y = df[\"HEUREUX_CLF\"]\n",
    "\n",
    "X, y = resample(X, y, random_state=42)\n",
    "\n",
    "X = X.iloc[0:n_max,:]\n",
    "y = y.iloc[0:n_max]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Number exemple: {y.shape[0]}\\n- training set: \\\n",
    "{y_train.shape[0]}\\n- test set: {y_test.shape[0]}\")\n",
    "print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "print(f\"Number of class: {len(np.unique(y))}\")\n",
    "for c in np.unique(y):\n",
    "    print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determination of optimal hyperparameters in 48.3 s\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 256} \n",
      "Accuracy Score of cross valdation 75.56%\n",
      "Random Forest, p=66\n",
      "Model score\n",
      "- Accuracy : 81.0 %\n",
      "- Precision : 80.7 % (Happy # positive class)\n",
      "- Recall : 93.1 %\n",
      "- F1 score : 86.4 %\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "n_estimators_range = [32,64,128,256,512]\n",
    "max_depth_range = [4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32,\n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced'}\n",
    "clf = RandomForestClassifier(**params)\n",
    "\n",
    "grid = GridSearchCV(clf, scoring='accuracy', param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Determination of optimal hyperparameters in {time.time() - startTime:0.1f} s\")\n",
    "print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "Accuracy Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "\n",
    "# Learning on full training set with optimals hyperparameters and score on test set\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "          'n_estimators' : grid.best_params_['n_estimators'],\n",
    "          'max_depth' : grid.best_params_['max_depth']}\n",
    "clf = RandomForestClassifier(**params).fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"Random Forest, p={X_train.shape[1]}\")\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM - Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_value = 20 # Nombre de valeurs testées pour l'hyperparamètre\n",
    "mean_score_svc = np.zeros(nb_value)\n",
    "C_log = np.logspace(-4,1,nb_value)\n",
    "cv = 3 # V-fold, nombre de fold\n",
    "\n",
    "mean_score_svc = np.empty(nb_value)\n",
    "std_scores_svc = np.empty(nb_value)\n",
    "\n",
    "np.random.seed(seed=42) \n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "for i, C in enumerate(C_log):\n",
    "    clf = SVC(C=C,\n",
    "              kernel = 'linear',\n",
    "              random_state=42, \n",
    "              class_weight='balanced')\n",
    "    \n",
    "    mean_score_svc[i] = 100*np.mean(1-cross_val_score(clf, \n",
    "                                                     X_train, \n",
    "                                                     y_train,\n",
    "                                                     cv=cv, \n",
    "                                                     scoring='accuracy'))\n",
    "    std_scores_svc[i] = 100*np.std(1-cross_val_score(clf, \n",
    "                                                    X_train, \n",
    "                                                    y_train, \n",
    "                                                    cv=cv, \n",
    "                                                    scoring='accuracy'))    \n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogx(C_log,mean_score_svc[:],'r',linewidth=2,label='moyenne (l1)')\n",
    "plt.semilogx(C_log,mean_score_svc[:]-0.5*std_scores_svc[:],\n",
    "             'r--', label=u'+/-0.5 écart type')\n",
    "plt.semilogx(C_log,mean_score_svc[:]+0.5*std_scores_svc[:],'r--')\n",
    "\n",
    "plt.xlabel(\"Valeur de pénalisation C = 1/lambda\")\n",
    "plt.ylabel(u\"Erreur de validation croisée (%)\\n(Taux moyen d'erreur de classification)\")\n",
    "plt.title(u\"Choix de l'hyperparamètre C\\npar validation croisée \\\n",
    "(V-fold avec V = %s)\" % (cv)) \n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(f\"Determination of optimal hyperparameters in {time.time() - startTime:0.1f} s\")\n",
    "print(\"Valeur optimale : C = %0.4f\" % (C_log[np.argmin(mean_score_svc)]))\n",
    "\n",
    "\n",
    "\n",
    "# Learning on full training set with optimals hyperparameters and score on test set\n",
    "params = {\n",
    "    'C' : C_log[np.argmin(mean_score_svc)],\n",
    "    'random_state' : 32, \n",
    "    'kernel' : 'linear',\n",
    "    'class_weight' : 'balanced'\n",
    "}\n",
    "clf = SVC(**params).fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"SCV linear kernel, p={X_train.shape[1]}\")\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "scoring='accuracy' \n",
    "step = 0.05\n",
    "\n",
    "clf = SVC(C=1,\n",
    "          kernel = 'linear',\n",
    "          random_state=42, \n",
    "          class_weight='balanced')\n",
    "\n",
    "rfecv = RFECV(estimator=clf, step=step, cv=StratifiedKFold(4),\n",
    "              scoring=scoring)\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(f\"Number of recurcive steps of {100*step:0.0f}% through {X_train.shape[1]} variables\")\n",
    "plt.ylabel(f\"Cross validation score \\n({scoring})\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "print(f\"Détermination des features optimales en %0.1f s\" % (time.time() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = rfecv.support_.copy()\n",
    "X_train = X_train[:,mask]\n",
    "X_test = X_test[:,mask]\n",
    "print(f\"Number of features: p={X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_value = 20 # Nombre de valeurs testées pour l'hyperparamètre\n",
    "mean_score_svc = np.zeros(nb_value)\n",
    "C_log = np.logspace(-4,1,nb_value)\n",
    "cv = 6 # V-fold, nombre de fold\n",
    "\n",
    "mean_score_svc = np.empty(nb_value)\n",
    "std_scores_svc = np.empty(nb_value)\n",
    "\n",
    "np.random.seed(seed=42) \n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "for i, C in enumerate(C_log):\n",
    "    clf = SVC(C=C,\n",
    "              kernel = 'linear',\n",
    "              random_state=42, \n",
    "              class_weight='balanced')\n",
    "    \n",
    "    mean_score_svc[i] = 100*np.mean(1-cross_val_score(clf, \n",
    "                                                     X_train, \n",
    "                                                     y_train,\n",
    "                                                     cv=cv, \n",
    "                                                     scoring='accuracy'))\n",
    "    std_scores_svc[i] = 100*np.std(1-cross_val_score(clf, \n",
    "                                                    X_train, \n",
    "                                                    y_train, \n",
    "                                                    cv=cv, \n",
    "                                                    scoring='accuracy'))    \n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogx(C_log,mean_score_svc[:],'r',linewidth=2,label='moyenne (l1)')\n",
    "plt.semilogx(C_log,mean_score_svc[:]-0.5*std_scores_svc[:],\n",
    "             'r--', label=u'+/-0.5 écart type')\n",
    "plt.semilogx(C_log,mean_score_svc[:]+0.5*std_scores_svc[:],'r--')\n",
    "\n",
    "plt.xlabel(\"Valeur de pénalisation C = 1/lambda\")\n",
    "plt.ylabel(u\"Erreur de validation croisée (%)\\n(Taux moyen d'erreur de classification)\")\n",
    "plt.title(u\"Choix de l'hyperparamètre C\\npar validation croisée \\\n",
    "(V-fold avec V = %s)\" % (cv)) \n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(f\"Determination of optimal hyperparameters in {time.time() - startTime:0.1f} s\")\n",
    "print(\"Valeur optimale : C = %0.4f\" % (C_log[np.argmin(mean_score_svc)]))\n",
    "\n",
    "\n",
    "\n",
    "# Learning on full training set with optimals hyperparameters and score on test set\n",
    "params = {\n",
    "    'C' : C_log[np.argmin(mean_score_svc)],\n",
    "    'random_state' : 32, \n",
    "    'kernel' : 'linear',\n",
    "    'class_weight' : 'balanced'\n",
    "}\n",
    "clf = SVC(**params).fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"SCV linear kernel, p={X_train.shape[1]}\")\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model valuation by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.loc[:,:]\n",
    "# reducing problem to a 2 class classification problem\n",
    "df[\"HEUREUX_CLF\"] = 0\n",
    "df.loc[df[\"HEUREUX\"]==4, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==3, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==5, \"HEUREUX_CLF\"] = None\n",
    "\n",
    "scope = lasso_50_features | indiv_act_features\n",
    "n_max = 12000\n",
    "df = df.loc[:,scope | {\"HEUREUX_CLF\"} ].dropna()\n",
    "features = df.loc[:,scope ].columns\n",
    "\n",
    "X = df.loc[:,scope]\n",
    "y = df[\"HEUREUX_CLF\"]\n",
    "\n",
    "X, y = resample(X, y, random_state=42)\n",
    "\n",
    "X = X.iloc[0:n_max,:]\n",
    "y = y.iloc[0:n_max]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Number exemple: {y.shape[0]}\\n- training set: \\\n",
    "{y_train.shape[0]}\\n- test set: {y_test.shape[0]}\")\n",
    "print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "print(f\"Number of class: {len(np.unique(y))}\")\n",
    "for c in np.unique(y):\n",
    "    print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading cdv data\n",
    "file = path_data / Path(\"clustTest1.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    clustTest1 = pd.read_csv(fp,  encoding='utf-8',low_memory=False, sep=\";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = dict()\n",
    "\n",
    "n_estimators_range = [16,32,64,128]\n",
    "max_depth_range = [2,4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "params = {'max_features' :'sqrt', \n",
    "          'random_state' : 32, \n",
    "          'min_samples_split' : 2, \n",
    "          'class_weight' : 'balanced'\n",
    "         }\n",
    "\n",
    "score_clustering_methods = []\n",
    "clustering_methods = clustTest1.columns[0:3]\n",
    "\n",
    "for method in clustering_methods:\n",
    "    print(f\"\\nAnalysis cluster method {method}\")\n",
    "    cluster_list = clustTest1[method].unique()\n",
    "    print(f\"liste of clusters : {cluster_list}\")\n",
    "    score_cluster = []\n",
    "    for cluster in cluster_list:\n",
    "        index_scope = clustTest1.loc[clustTest1[method]==cluster,:].index\n",
    "        print(f\"cluster {cluster} : {len(index_scope)} elements\")\n",
    "        \n",
    "        # treating remaining missing values        \n",
    "        n_max = 2000\n",
    "        df_tmp = df.loc[index_scope,lasso_20_features | indiv_act_features | {\"HEUREUX_CLF\"} ].dropna()\n",
    "        features = df.loc[:,lasso_20_features | indiv_act_features ].columns\n",
    "\n",
    "        X = df_tmp.loc[:,lasso_20_features | indiv_act_features]\n",
    "        y = df_tmp[\"HEUREUX_CLF\"]\n",
    "\n",
    "        X, y = resample(X, y)\n",
    "\n",
    "        X = X.iloc[0:n_max,:]\n",
    "        y = y.iloc[0:n_max]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=42)\n",
    "\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "                \n",
    "        \n",
    "        print(f\"Number exemple: {y.shape[0]}\\n\\\n",
    "        - training set: {y_train.shape[0]}\\n\\\n",
    "        - test set: {y_test.shape[0]}\")\n",
    "        print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "        print(f\"Number of class: {len(np.unique(y))}\")\n",
    "        for c in np.unique(y):\n",
    "            print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")\n",
    "            \n",
    "            \n",
    "        startTime = time.time()\n",
    "        clf = RandomForestClassifier(**params)\n",
    "        grid = GridSearchCV(clf, \n",
    "                            scoring='accuracy', \n",
    "                            param_grid=param_grid)\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "        Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "\n",
    "        # Learning on full training set with optimals hyperparameters and score on test set\n",
    "        params_opt = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "                      'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "                      'n_estimators' : grid.best_params_['n_estimators'],\n",
    "                      'max_depth' : grid.best_params_['max_depth']}\n",
    "        clf = RandomForestClassifier(**params_opt).fit(X_train, y_train)\n",
    "\n",
    "            \n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        f1 = f1_score(y_test, y_test_pred)\n",
    "        p = precision_score(y_test, y_test_pred)\n",
    "        r = recall_score(y_test, y_test_pred)            \n",
    "\n",
    "        res  = {'f1_score' : f1,\n",
    "                'accuracy' : accuracy,\n",
    "                'precision' : p,\n",
    "                'recall' : r}\n",
    "            \n",
    "        cl = {'cluster' : cluster,\n",
    "              'model' : 'RandomForestClassifier',\n",
    "              'params' : params_opt,\n",
    "              'metrics' : res\n",
    "             }\n",
    "         \n",
    "        score_cluster.append(cl)\n",
    "        \n",
    "    d = {'clustering_method' : method,\n",
    "         'cluster_scores' : score_cluster\n",
    "        }\n",
    "    score_clustering_methods.append(d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(f\"F1 on full dataset : {100*score_rf['f1_macro']:0.1f}%\")\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']}, f1 macro {100*score_cluster['metrics']['f1_score']:0.1f}%\")  \n",
    "        average_score = average_score + score_cluster['metrics']['f1_score']\n",
    "    average_score = average_score / (i+1)\n",
    "    print(f\"average f1 on clusters {100*average_score:0.1f}%\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"F1 on full dataset : {100*score_rf['f1_macro']:0.1f}%\")\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']}, accuracy {100*score_cluster['metrics']['accuracy']:0.1f}%\")  \n",
    "        average_score = average_score + score_cluster['metrics']['accuracy']\n",
    "    average_score = average_score / (i+1)\n",
    "    print(f\"average accuracy on clusters {100*average_score:0.1f}%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Code factorisation...  \n",
    "Evaluation of LinearSVM, LogisticalRegression, RandomForest on various subset of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = [100,50,20,10]\n",
    "models =  ['RFE_LogisticRegression_', 'RFE_RandomForestClassifier_','RFE_LinearSVC_']\n",
    "keys = [m+str(n)+'_features' for m in models for n in n_features]\n",
    "keys +=['SelectFromModel_LinearSCV_features','SelectFromModel_LogisticRegression_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RFE_LogisticRegression_100_features',\n",
       " 'RFE_LogisticRegression_50_features',\n",
       " 'RFE_LogisticRegression_20_features',\n",
       " 'RFE_LogisticRegression_10_features',\n",
       " 'RFE_RandomForestClassifier_100_features',\n",
       " 'RFE_RandomForestClassifier_50_features',\n",
       " 'RFE_RandomForestClassifier_20_features',\n",
       " 'RFE_RandomForestClassifier_10_features',\n",
       " 'RFE_LinearSVC_100_features',\n",
       " 'RFE_LinearSVC_50_features',\n",
       " 'RFE_LinearSVC_20_features',\n",
       " 'RFE_LinearSVC_10_features',\n",
       " 'SelectFromModel_LinearSCV_features',\n",
       " 'SelectFromModel_LogisticRegression_features']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature selection methode : RFE_LogisticRegression_100_features\n",
      "Number of features: p=144\n",
      "Determination of optimal hyperparameters in 44.2 s\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 512} \n",
      "    Accuracy Score of cross valdation 75.31%\n",
      "Random Forest, p=144\n",
      "Model score\n",
      "- Accuracy : 77.5 %\n",
      "- Precision : 78.5 % (Happy # positive class)\n",
      "- Recall : 91.4 %\n",
      "- F1 score : 84.4 %\n",
      "\n",
      "feature selection methode : RFE_LogisticRegression_50_features\n",
      "Number of features: p=95\n",
      "Determination of optimal hyperparameters in 40.1 s\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "    Accuracy Score of cross valdation 75.44%\n",
      "Random Forest, p=95\n",
      "Model score\n",
      "- Accuracy : 79.5 %\n",
      "- Precision : 79.3 % (Happy # positive class)\n",
      "- Recall : 92.7 %\n",
      "- F1 score : 85.5 %\n",
      "\n",
      "feature selection methode : RFE_LogisticRegression_20_features\n",
      "Number of features: p=66\n",
      "Determination of optimal hyperparameters in 37.8 s\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 256} \n",
      "    Accuracy Score of cross valdation 75.56%\n",
      "Random Forest, p=66\n",
      "Model score\n",
      "- Accuracy : 81.0 %\n",
      "- Precision : 80.7 % (Happy # positive class)\n",
      "- Recall : 93.1 %\n",
      "- F1 score : 86.4 %\n",
      "\n",
      "feature selection methode : RFE_LogisticRegression_10_features\n",
      "Number of features: p=58\n",
      "Determination of optimal hyperparameters in 36.7 s\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 64} \n",
      "    Accuracy Score of cross valdation 73.38%\n",
      "Random Forest, p=58\n",
      "Model score\n",
      "- Accuracy : 78.0 %\n",
      "- Precision : 79.5 % (Happy # positive class)\n",
      "- Recall : 89.2 %\n",
      "- F1 score : 84.1 %\n",
      "\n",
      "feature selection methode : RFE_RandomForestClassifier_100_features\n",
      "Number of features: p=143\n",
      "Determination of optimal hyperparameters in 61.5 s\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 256} \n",
      "    Accuracy Score of cross valdation 75.44%\n",
      "Random Forest, p=143\n",
      "Model score\n",
      "- Accuracy : 76.8 %\n",
      "- Precision : 79.6 % (Happy # positive class)\n",
      "- Recall : 86.6 %\n",
      "- F1 score : 83.0 %\n",
      "\n",
      "feature selection methode : RFE_RandomForestClassifier_50_features\n",
      "Number of features: p=93\n",
      "Determination of optimal hyperparameters in 47.6 s\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "    Accuracy Score of cross valdation 74.12%\n",
      "Random Forest, p=93\n",
      "Model score\n",
      "- Accuracy : 78.5 %\n",
      "- Precision : 78.1 % (Happy # positive class)\n",
      "- Recall : 92.2 %\n",
      "- F1 score : 84.5 %\n",
      "\n",
      "feature selection methode : RFE_RandomForestClassifier_20_features\n",
      "Number of features: p=68\n",
      "Determination of optimal hyperparameters in 46.8 s\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 64} \n",
      "    Accuracy Score of cross valdation 75.62%\n",
      "Random Forest, p=68\n",
      "Model score\n",
      "- Accuracy : 77.2 %\n",
      "- Precision : 79.7 % (Happy # positive class)\n",
      "- Recall : 88.4 %\n",
      "- F1 score : 83.8 %\n",
      "\n",
      "feature selection methode : RFE_RandomForestClassifier_10_features\n",
      "Number of features: p=58\n",
      "Determination of optimal hyperparameters in 39.0 s\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 256} \n",
      "    Accuracy Score of cross valdation 74.06%\n",
      "Random Forest, p=58\n",
      "Model score\n",
      "- Accuracy : 74.2 %\n",
      "- Precision : 80.8 % (Happy # positive class)\n",
      "- Recall : 79.2 %\n",
      "- F1 score : 80.0 %\n",
      "\n",
      "feature selection methode : RFE_LinearSVC_100_features\n",
      "Number of features: p=147\n",
      "Determination of optimal hyperparameters in 55.6 s\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 64} \n",
      "    Accuracy Score of cross valdation 75.12%\n",
      "Random Forest, p=147\n",
      "Model score\n",
      "- Accuracy : 72.0 %\n",
      "- Precision : 77.6 % (Happy # positive class)\n",
      "- Recall : 81.6 %\n",
      "- F1 score : 79.6 %\n",
      "\n",
      "feature selection methode : RFE_LinearSVC_50_features\n",
      "Number of features: p=98\n",
      "Determination of optimal hyperparameters in 85.2 s\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 256} \n",
      "    Accuracy Score of cross valdation 75.25%\n",
      "Random Forest, p=98\n",
      "Model score\n",
      "- Accuracy : 75.0 %\n",
      "- Precision : 77.9 % (Happy # positive class)\n",
      "- Recall : 87.3 %\n",
      "- F1 score : 82.3 %\n",
      "\n",
      "feature selection methode : RFE_LinearSVC_20_features\n",
      "Number of features: p=68\n",
      "Determination of optimal hyperparameters in 62.0 s\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 32} \n",
      "    Accuracy Score of cross valdation 75.88%\n",
      "Random Forest, p=68\n",
      "Model score\n",
      "- Accuracy : 73.2 %\n",
      "- Precision : 77.6 % (Happy # positive class)\n",
      "- Recall : 84.3 %\n",
      "- F1 score : 80.8 %\n",
      "\n",
      "feature selection methode : RFE_LinearSVC_10_features\n",
      "Number of features: p=58\n",
      "Determination of optimal hyperparameters in 56.9 s\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "    Accuracy Score of cross valdation 72.75%\n",
      "Random Forest, p=58\n",
      "Model score\n",
      "- Accuracy : 75.8 %\n",
      "- Precision : 76.5 % (Happy # positive class)\n",
      "- Recall : 90.4 %\n",
      "- F1 score : 82.9 %\n",
      "\n",
      "feature selection methode : SelectFromModel_LinearSCV_features\n",
      "Number of features: p=262\n",
      "Determination of optimal hyperparameters in 74.6 s\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 64} \n",
      "    Accuracy Score of cross valdation 75.31%\n",
      "Random Forest, p=262\n",
      "Model score\n",
      "- Accuracy : 74.2 %\n",
      "- Precision : 79.1 % (Happy # positive class)\n",
      "- Recall : 83.5 %\n",
      "- F1 score : 81.2 %\n",
      "\n",
      "feature selection methode : SelectFromModel_LogisticRegression_features\n",
      "Number of features: p=96\n",
      "Determination of optimal hyperparameters in 62.2 s\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 256} \n",
      "    Accuracy Score of cross valdation 75.56%\n",
      "Random Forest, p=96\n",
      "Model score\n",
      "- Accuracy : 78.2 %\n",
      "- Precision : 78.5 % (Happy # positive class)\n",
      "- Recall : 91.5 %\n",
      "- F1 score : 84.5 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_max = 2000\n",
    "\n",
    "for k in keys:\n",
    "    scope = dict_features_sets[k] | indiv_act_features\n",
    "    print(f\"feature selection methode : {k}\")\n",
    "\n",
    "    \n",
    "    df = dataset.loc[:,:]\n",
    "    # reducing problem to a 2 class classification problem\n",
    "    df[\"HEUREUX_CLF\"] = 0\n",
    "    df.loc[df[\"HEUREUX\"]==4, \"HEUREUX_CLF\"] = 1\n",
    "    df.loc[df[\"HEUREUX\"]==3, \"HEUREUX_CLF\"] = 1\n",
    "    df.loc[df[\"HEUREUX\"]==5, \"HEUREUX_CLF\"] = None\n",
    "    \n",
    "    \n",
    "    df = df.loc[:,scope | {\"HEUREUX_CLF\"} ].dropna()\n",
    "    features = df.loc[:,scope ].columns\n",
    "\n",
    "    X = df.loc[:,scope]\n",
    "    y = df[\"HEUREUX_CLF\"]\n",
    "\n",
    "    Xs, ys = resample(X, y, random_state=42)\n",
    "\n",
    "    Xs = Xs.iloc[0:n_max,:]\n",
    "    ys = ys.iloc[0:n_max]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xs, ys, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "#    print(f\"Number exemple: {y.shape[0]}\\n- training set: \\\n",
    "#    {y_train.shape[0]}\\n- test set: {y_test.shape[0]}\")\n",
    "    print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "#    print(f\"Number of class: {len(np.unique(y))}\")\n",
    "#    for c in np.unique(y):\n",
    "#        print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")\n",
    "\n",
    "\n",
    "\n",
    "    startTime = time.time()\n",
    "    n_estimators_range = [32,64,128,256,512]\n",
    "    max_depth_range = [4,8,16,32,64] \n",
    "    param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "\n",
    "    params = {'max_features' :'sqrt', 'random_state' : 32,\n",
    "              'min_samples_split' : 2, 'class_weight' : 'balanced'}\n",
    "    clf = RandomForestClassifier(**params)\n",
    "\n",
    "    grid = GridSearchCV(clf, scoring='accuracy', param_grid=param_grid)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Determination of optimal hyperparameters in {time.time() - startTime:0.1f} s\")\n",
    "    print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "    Accuracy Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "\n",
    "    # Learning on full training set with optimals hyperparameters and score on test set\n",
    "    params = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "              'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "              'n_estimators' : grid.best_params_['n_estimators'],\n",
    "              'max_depth' : grid.best_params_['max_depth']}\n",
    "    clf = RandomForestClassifier(**params).fit(X_train, y_train)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    print(f\"Random Forest, p={X_train.shape[1]}\")\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    p = precision_score(y_test, y_test_pred)\n",
    "    r = recall_score(y_test, y_test_pred)\n",
    "    print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "    print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "    print(f\"- Recall : {r*100:0.1f} %\")\n",
    "    print(f\"- F1 score : {f1*100:0.1f} %\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature selection methode : RFE_LogisticRegression_100_features\n",
      "Number of features: p=144\n",
      "Determination of optimal hyperparameters in 12.0 s\n",
      "Valeur optimale : C = 0.0006\n",
      "SCV linear kernel, p=144\n",
      "Model score\n",
      "- Accuracy : 68.0 %\n",
      "- Precision : 78.8 % (Happy # positive class)\n",
      "- Recall : 71.2 %\n",
      "- F1 score : 74.8 %\n",
      "\n",
      "feature selection methode : RFE_LogisticRegression_50_features\n",
      "Number of features: p=95\n",
      "Determination of optimal hyperparameters in 4.0 s\n",
      "Valeur optimale : C = 0.0006\n",
      "SCV linear kernel, p=95\n",
      "Model score\n",
      "- Accuracy : 72.5 %\n",
      "- Precision : 82.6 % (Happy # positive class)\n",
      "- Recall : 73.1 %\n",
      "- F1 score : 77.6 %\n",
      "\n",
      "feature selection methode : RFE_LogisticRegression_20_features\n",
      "Number of features: p=66\n",
      "Determination of optimal hyperparameters in 3.9 s\n",
      "Valeur optimale : C = 0.0011\n",
      "SCV linear kernel, p=66\n",
      "Model score\n",
      "- Accuracy : 70.5 %\n",
      "- Precision : 81.7 % (Happy # positive class)\n",
      "- Recall : 70.4 %\n",
      "- F1 score : 75.6 %\n",
      "\n",
      "feature selection methode : RFE_LogisticRegression_10_features\n",
      "Number of features: p=58\n",
      "Determination of optimal hyperparameters in 4.0 s\n",
      "Valeur optimale : C = 0.0011\n",
      "SCV linear kernel, p=58\n",
      "Model score\n",
      "- Accuracy : 70.2 %\n",
      "- Precision : 81.3 % (Happy # positive class)\n",
      "- Recall : 70.4 %\n",
      "- F1 score : 75.5 %\n",
      "\n",
      "feature selection methode : RFE_RandomForestClassifier_100_features\n",
      "Number of features: p=143\n",
      "Determination of optimal hyperparameters in 30.6 s\n",
      "Valeur optimale : C = 0.0011\n",
      "SCV linear kernel, p=143\n",
      "Model score\n",
      "- Accuracy : 73.5 %\n",
      "- Precision : 82.2 % (Happy # positive class)\n",
      "- Recall : 76.0 %\n",
      "- F1 score : 79.0 %\n",
      "\n",
      "feature selection methode : RFE_RandomForestClassifier_50_features\n",
      "Number of features: p=93\n",
      "Determination of optimal hyperparameters in 9.3 s\n",
      "Valeur optimale : C = 0.0003\n",
      "SCV linear kernel, p=93\n",
      "Model score\n",
      "- Accuracy : 72.0 %\n",
      "- Precision : 79.4 % (Happy # positive class)\n",
      "- Recall : 75.7 %\n",
      "- F1 score : 77.5 %\n",
      "\n",
      "feature selection methode : RFE_RandomForestClassifier_20_features\n",
      "Number of features: p=68\n",
      "Determination of optimal hyperparameters in 3.0 s\n",
      "Valeur optimale : C = 0.0003\n",
      "SCV linear kernel, p=68\n",
      "Model score\n",
      "- Accuracy : 71.0 %\n",
      "- Precision : 82.1 % (Happy # positive class)\n",
      "- Recall : 72.3 %\n",
      "- F1 score : 76.9 %\n",
      "\n",
      "feature selection methode : RFE_RandomForestClassifier_10_features\n",
      "Number of features: p=58\n",
      "Determination of optimal hyperparameters in 1.7 s\n",
      "Valeur optimale : C = 0.0003\n",
      "SCV linear kernel, p=58\n",
      "Model score\n",
      "- Accuracy : 69.5 %\n",
      "- Precision : 80.5 % (Happy # positive class)\n",
      "- Recall : 70.0 %\n",
      "- F1 score : 74.9 %\n",
      "\n",
      "feature selection methode : RFE_LinearSVC_100_features\n",
      "Number of features: p=147\n",
      "Determination of optimal hyperparameters in 24.5 s\n",
      "Valeur optimale : C = 0.2637\n",
      "SCV linear kernel, p=147\n",
      "Model score\n",
      "- Accuracy : 68.0 %\n",
      "- Precision : 79.3 % (Happy # positive class)\n",
      "- Recall : 70.4 %\n",
      "- F1 score : 74.6 %\n",
      "\n",
      "feature selection methode : RFE_LinearSVC_50_features\n",
      "Number of features: p=98\n",
      "Determination of optimal hyperparameters in 10.6 s\n",
      "Valeur optimale : C = 0.2637\n",
      "SCV linear kernel, p=98\n",
      "Model score\n",
      "- Accuracy : 70.0 %\n",
      "- Precision : 80.5 % (Happy # positive class)\n",
      "- Recall : 72.7 %\n",
      "- F1 score : 76.4 %\n",
      "\n",
      "feature selection methode : RFE_LinearSVC_20_features\n",
      "Number of features: p=68\n",
      "Determination of optimal hyperparameters in 3.1 s\n",
      "Valeur optimale : C = 0.0011\n",
      "SCV linear kernel, p=68\n",
      "Model score\n",
      "- Accuracy : 70.0 %\n",
      "- Precision : 81.5 % (Happy # positive class)\n",
      "- Recall : 71.2 %\n",
      "- F1 score : 76.0 %\n",
      "\n",
      "feature selection methode : RFE_LinearSVC_10_features\n",
      "Number of features: p=58\n",
      "Determination of optimal hyperparameters in 2.2 s\n",
      "Valeur optimale : C = 0.4833\n",
      "SCV linear kernel, p=58\n",
      "Model score\n",
      "- Accuracy : 69.8 %\n",
      "- Precision : 80.1 % (Happy # positive class)\n",
      "- Recall : 71.2 %\n",
      "- F1 score : 75.4 %\n",
      "\n",
      "feature selection methode : SelectFromModel_LinearSCV_features\n",
      "Number of features: p=262\n",
      "Determination of optimal hyperparameters in 41.1 s\n",
      "Valeur optimale : C = 0.0003\n",
      "SCV linear kernel, p=262\n",
      "Model score\n",
      "- Accuracy : 66.2 %\n",
      "- Precision : 78.7 % (Happy # positive class)\n",
      "- Recall : 67.8 %\n",
      "- F1 score : 72.8 %\n",
      "\n",
      "feature selection methode : SelectFromModel_LogisticRegression_features\n",
      "Number of features: p=96\n",
      "Determination of optimal hyperparameters in 3.8 s\n",
      "Valeur optimale : C = 0.0011\n",
      "SCV linear kernel, p=96\n",
      "Model score\n",
      "- Accuracy : 73.8 %\n",
      "- Precision : 82.4 % (Happy # positive class)\n",
      "- Recall : 75.8 %\n",
      "- F1 score : 79.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_max = 2000\n",
    "\n",
    "for k in keys:\n",
    "    scope = dict_features_sets[k] | indiv_act_features\n",
    "    print(f\"feature selection methode : {k}\")\n",
    "\n",
    "    \n",
    "    df = dataset.loc[:,:]\n",
    "    # reducing problem to a 2 class classification problem\n",
    "    df[\"HEUREUX_CLF\"] = 0\n",
    "    df.loc[df[\"HEUREUX\"]==4, \"HEUREUX_CLF\"] = 1\n",
    "    df.loc[df[\"HEUREUX\"]==3, \"HEUREUX_CLF\"] = 1\n",
    "    df.loc[df[\"HEUREUX\"]==5, \"HEUREUX_CLF\"] = None\n",
    "    \n",
    "    \n",
    "    df = df.loc[:,scope | {\"HEUREUX_CLF\"} ].dropna()\n",
    "    features = df.loc[:,scope ].columns\n",
    "\n",
    "    X = df.loc[:,scope]\n",
    "    y = df[\"HEUREUX_CLF\"]\n",
    "\n",
    "    Xs, ys = resample(X, y, random_state=42)\n",
    "\n",
    "    Xs = Xs.iloc[0:n_max,:]\n",
    "    ys = ys.iloc[0:n_max]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xs, ys, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "#    print(f\"Number exemple: {y.shape[0]}\\n- training set: \\\n",
    "#    {y_train.shape[0]}\\n- test set: {y_test.shape[0]}\")\n",
    "    print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "#    print(f\"Number of class: {len(np.unique(y))}\")\n",
    "#    for c in np.unique(y):\n",
    "#        print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")\n",
    "\n",
    "\n",
    "\n",
    "    nb_value = 20 # Nombre de valeurs testées pour l'hyperparamètre\n",
    "    mean_score_svc = np.zeros(nb_value)\n",
    "    C_log = np.logspace(-4,1,nb_value)\n",
    "    cv = 3 # V-fold, nombre de fold\n",
    "\n",
    "    mean_score_svc = np.empty(nb_value)\n",
    "    std_scores_svc = np.empty(nb_value)\n",
    "\n",
    "    np.random.seed(seed=42) \n",
    "\n",
    "    startTime = time.time()\n",
    "\n",
    "    for i, C in enumerate(C_log):\n",
    "        clf = LinearSVC(C=C,\n",
    "                        dual = False,\n",
    "                        random_state=42, \n",
    "                        class_weight='balanced')\n",
    "    \n",
    "        mean_score_svc[i] = 100*np.mean(1-cross_val_score(clf, \n",
    "                                                         X_train, \n",
    "                                                         y_train,\n",
    "                                                         cv=cv, \n",
    "                                                         scoring='accuracy'))\n",
    "        std_scores_svc[i] = 100*np.std(1-cross_val_score(clf, \n",
    "                                                        X_train, \n",
    "                                                        y_train, \n",
    "                                                        cv=cv, \n",
    "                                                        scoring='accuracy'))    \n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Determination of optimal hyperparameters in {time.time() - startTime:0.1f} s\")\n",
    "    print(\"Valeur optimale : C = %0.4f\" % (C_log[np.argmin(mean_score_svc)]))\n",
    "\n",
    "\n",
    "\n",
    "    # Learning on full training set with optimals hyperparameters and score on test set\n",
    "    params = {\n",
    "        'C' : C_log[np.argmin(mean_score_svc)],\n",
    "        'random_state' : 32, \n",
    "        'dual' : False,\n",
    "        'class_weight' : 'balanced'\n",
    "    }\n",
    "    clf = LinearSVC(**params).fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    print(f\"SCV linear kernel, p={X_train.shape[1]}\")\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    p = precision_score(y_test, y_test_pred)\n",
    "    r = recall_score(y_test, y_test_pred)\n",
    "    print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "    print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "    print(f\"- Recall : {r*100:0.1f} %\")\n",
    "    print(f\"- F1 score : {f1*100:0.1f} %\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valuation of the same model family on clusters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "file = path_data / Path(\"dataset_2017_2018.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    dataset_2017_2018 = pd.read_csv(fp,  encoding='utf-8',low_memory=False, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading cdv data\n",
    "file = path_data / Path(\"clustTest1.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    clustTest1 = pd.read_csv(fp,  encoding='utf-8',low_memory=False, sep=\";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Full scope 2017-2018 - training set 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number exemple: 5722\n",
      "- training set: 1600\n",
      "- test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n"
     ]
    }
   ],
   "source": [
    "df = dataset_2017_2018.loc[:,:]\n",
    "# reducing problem to a 2 class classification problem\n",
    "df[\"HEUREUX_CLF\"] = 0\n",
    "df.loc[df[\"HEUREUX\"]==4, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==3, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==5, \"HEUREUX_CLF\"] = None\n",
    "\n",
    "scope = ( RFE_LogisticRegression_20_features | indiv_act_features )  & set(dataset_2017_2018.columns)\n",
    "\n",
    "\n",
    "df = df.loc[:,scope | {\"HEUREUX_CLF\"} ].dropna()\n",
    "features = df.loc[:,scope ].columns\n",
    "\n",
    "X = df.loc[:,scope]\n",
    "y = df[\"HEUREUX_CLF\"]\n",
    "\n",
    "n_max = 2000\n",
    "Xs, ys = resample(X, y, random_state=42)\n",
    "\n",
    "Xs = Xs.iloc[0:n_max,:]\n",
    "ys = ys.iloc[0:n_max]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Number exemple: {y.shape[0]}\\n- training set: \\\n",
    "{y_train.shape[0]}\\n- test set: {y_test.shape[0]}\")\n",
    "print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "print(f\"Number of class: {len(np.unique(y))}\")\n",
    "for c in np.unique(y):\n",
    "    print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determination of optimal hyperparameters in 51.1 s\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 256} \n",
      "Accuracy Score of cross valdation 76.44%\n",
      "Random Forest, p=66\n",
      "Model score\n",
      "- Accuracy : 81.0 %\n",
      "- Precision : 80.0 % (Happy # positive class)\n",
      "- Recall : 92.8 %\n",
      "- F1 score : 85.9 %\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "n_estimators_range = [32,64,128,256,512]\n",
    "max_depth_range = [4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32,\n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced'}\n",
    "clf = RandomForestClassifier(**params)\n",
    "\n",
    "grid = GridSearchCV(clf, scoring='accuracy', param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Determination of optimal hyperparameters in {time.time() - startTime:0.1f} s\")\n",
    "print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "Accuracy Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "\n",
    "# Learning on full training set with optimals hyperparameters and score on test set\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "          'n_estimators' : grid.best_params_['n_estimators'],\n",
    "          'max_depth' : grid.best_params_['max_depth']}\n",
    "clf = RandomForestClassifier(**params).fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"Random Forest, p={X_train.shape[1]}\")\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation on each clusters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators_range = [16,32,64,128]\n",
    "max_depth_range = [2,4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "params = {'max_features' :'sqrt', \n",
    "          'random_state' : 32, \n",
    "          'min_samples_split' : 2, \n",
    "          'class_weight' : 'balanced'\n",
    "         }\n",
    "\n",
    "n_max = 2000\n",
    "\n",
    "scope = ( RFE_LogisticRegression_20_features | indiv_act_features )  & set(dataset_2017_2018.columns)\n",
    "features = df.loc[:,scope].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust1\n",
      "liste of clusters : [1 2 3 4 5 6]\n",
      "++++++++++++\n",
      "cluster 1 : 295 elements\n",
      "Number exemple: 271\n",
      "        - training set: 216\n",
      "        - test set: 55\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 16} \n",
      "        Score of cross valdation 80.09%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 1729 elements\n",
      "Number exemple: 1691\n",
      "        - training set: 1352\n",
      "        - test set: 339\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "        Score of cross valdation 85.80%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 3633 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 80.31%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 218 elements\n",
      "Number exemple: 201\n",
      "        - training set: 160\n",
      "        - test set: 41\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 128} \n",
      "        Score of cross valdation 89.38%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 137 elements\n",
      "Number exemple: 102\n",
      "        - training set: 81\n",
      "        - test set: 21\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 32} \n",
      "        Score of cross valdation 85.19%\n",
      "\n",
      "++++++++++++\n",
      "cluster 6 : 24 elements\n",
      "Number exemple: 20\n",
      "        - training set: 16\n",
      "        - test set: 4\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 128} \n",
      "        Score of cross valdation 62.50%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust2\n",
      "liste of clusters : [4 6 5 1 3 2 7]\n",
      "++++++++++++\n",
      "cluster 4 : 212 elements\n",
      "Number exemple: 194\n",
      "        - training set: 155\n",
      "        - test set: 39\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 128} \n",
      "        Score of cross valdation 85.81%\n",
      "\n",
      "++++++++++++\n",
      "cluster 6 : 1137 elements\n",
      "Number exemple: 1120\n",
      "        - training set: 896\n",
      "        - test set: 224\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 32} \n",
      "        Score of cross valdation 85.04%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 750 elements\n",
      "Number exemple: 732\n",
      "        - training set: 585\n",
      "        - test set: 147\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "        Score of cross valdation 85.47%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 1257 elements\n",
      "Number exemple: 1098\n",
      "        - training set: 878\n",
      "        - test set: 220\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 81.21%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 1254 elements\n",
      "Number exemple: 1205\n",
      "        - training set: 964\n",
      "        - test set: 241\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "        Score of cross valdation 84.85%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 857 elements\n",
      "Number exemple: 818\n",
      "        - training set: 654\n",
      "        - test set: 164\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 16} \n",
      "        Score of cross valdation 83.49%\n",
      "\n",
      "++++++++++++\n",
      "cluster 7 : 569 elements\n",
      "Number exemple: 555\n",
      "        - training set: 444\n",
      "        - test set: 111\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 16} \n",
      "        Score of cross valdation 85.59%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust3\n",
      "liste of clusters : [5 4 1 2 3]\n",
      "++++++++++++\n",
      "cluster 5 : 373 elements\n",
      "Number exemple: 363\n",
      "        - training set: 290\n",
      "        - test set: 73\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "        Score of cross valdation 79.31%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 2682 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 32} \n",
      "        Score of cross valdation 83.25%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 1593 elements\n",
      "Number exemple: 1433\n",
      "        - training set: 1146\n",
      "        - test set: 287\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "        Score of cross valdation 82.29%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 1246 elements\n",
      "Number exemple: 1203\n",
      "        - training set: 962\n",
      "        - test set: 241\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 85.24%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 142 elements\n",
      "Number exemple: 105\n",
      "        - training set: 84\n",
      "        - test set: 21\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 36.8%\n",
      "class 1 : 63.2%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 80.95%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_clustering_methods = []\n",
    "clustering_methods = clustTest1.columns[0:3]\n",
    "\n",
    "for method in clustering_methods:\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"\\nAnalysis cluster method {method}\")\n",
    "    cluster_list = clustTest1[method].unique()\n",
    "    print(f\"liste of clusters : {cluster_list}\")\n",
    "    score_cluster = []\n",
    "    for cluster in cluster_list:\n",
    "        index_scope = clustTest1.loc[clustTest1[method]==cluster,:].index\n",
    "        print(\"++++++++++++\")\n",
    "        print(f\"cluster {cluster} : {len(index_scope)} elements\")\n",
    "        \n",
    "        Xc = X.loc[index_scope.intersection(X.index),:]\n",
    "        yc = y[index_scope.intersection(X.index)]\n",
    "        \n",
    "        Xs, ys = resample(Xc, yc, random_state=42)\n",
    "        \n",
    "        Xs = Xs.iloc[0:n_max,:]\n",
    "        ys = ys.iloc[0:n_max]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(Xs, ys,\n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=42)\n",
    "\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "                \n",
    "        print(f\"Number exemple: {ys.shape[0]}\\n\\\n",
    "        - training set: {y_train.shape[0]}\\n\\\n",
    "        - test set: {y_test.shape[0]}\")\n",
    "        print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "        print(f\"Number of class: {len(np.unique(y))}\")\n",
    "        for c in np.unique(y):\n",
    "            print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")\n",
    "            \n",
    "            \n",
    "        startTime = time.time()\n",
    "        clf = RandomForestClassifier(**params)\n",
    "        grid = GridSearchCV(clf, \n",
    "                            scoring='accuracy', \n",
    "                            param_grid=param_grid)\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "        Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "        print()\n",
    "\n",
    "        # Learning on full training set with optimals hyperparameters and score on test set\n",
    "        params_opt = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "                      'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "                      'n_estimators' : grid.best_params_['n_estimators'],\n",
    "                      'max_depth' : grid.best_params_['max_depth']}\n",
    "        clf = RandomForestClassifier(**params_opt).fit(X_train, y_train)\n",
    "\n",
    "            \n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        f1 = f1_score(y_test, y_test_pred)\n",
    "        p = precision_score(y_test, y_test_pred)\n",
    "        r = recall_score(y_test, y_test_pred)            \n",
    "\n",
    "        res  = {'f1_score' : f1,\n",
    "                'accuracy' : accuracy,\n",
    "                'precision' : p,\n",
    "                'recall' : r}\n",
    "            \n",
    "        cl = {'cluster' : cluster,\n",
    "              'model' : 'RandomForestClassifier',\n",
    "              'params' : params_opt,\n",
    "              'metrics' : res\n",
    "             }\n",
    "         \n",
    "        score_cluster.append(cl)\n",
    "        \n",
    "    d = {'clustering_method' : method,\n",
    "         'cluster_scores' : score_cluster\n",
    "        }\n",
    "    score_clustering_methods.append(d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 66)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method clust1:\n",
      "cluster 1, f1 macro 82.1%\n",
      "cluster 2, f1 macro 91.3%\n",
      "cluster 3, f1 macro 85.9%\n",
      "cluster 4, f1 macro 85.7%\n",
      "cluster 5, f1 macro 60.9%\n",
      "cluster 6, f1 macro 80.0%\n",
      "average f1 on clusters 81.0%\n",
      "method clust2:\n",
      "cluster 4, f1 macro 87.8%\n",
      "cluster 6, f1 macro 91.8%\n",
      "cluster 5, f1 macro 90.6%\n",
      "cluster 1, f1 macro 86.2%\n",
      "cluster 3, f1 macro 90.0%\n",
      "cluster 2, f1 macro 92.4%\n",
      "cluster 7, f1 macro 84.1%\n",
      "average f1 on clusters 89.0%\n",
      "method clust3:\n",
      "cluster 5, f1 macro 85.4%\n",
      "cluster 4, f1 macro 89.0%\n",
      "cluster 1, f1 macro 88.6%\n",
      "cluster 2, f1 macro 95.3%\n",
      "cluster 3, f1 macro 91.7%\n",
      "average f1 on clusters 90.0%\n"
     ]
    }
   ],
   "source": [
    "#print(f\"F1 on full dataset : {100*score_rf['f1_macro']:0.1f}%\")\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']}, f1 macro {100*score_cluster['metrics']['f1_score']:0.1f}%\")  \n",
    "        average_score = average_score + score_cluster['metrics']['f1_score']\n",
    "    average_score = average_score / (i+1)\n",
    "    print(f\"average f1 on clusters {100*average_score:0.1f}%\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method clust1:\n",
      "cluster 1, accuracy 81.8%\n",
      "cluster 2, accuracy 88.2%\n",
      "cluster 3, accuracy 79.5%\n",
      "cluster 4, accuracy 80.5%\n",
      "cluster 5, accuracy 57.1%\n",
      "cluster 6, accuracy 75.0%\n",
      "average accuracy on clusters 77.0%\n",
      "method clust2:\n",
      "cluster 4, accuracy 87.2%\n",
      "cluster 6, accuracy 89.3%\n",
      "cluster 5, accuracy 87.1%\n",
      "cluster 1, accuracy 84.1%\n",
      "cluster 3, accuracy 86.3%\n",
      "cluster 2, accuracy 89.6%\n",
      "cluster 7, accuracy 84.7%\n",
      "average accuracy on clusters 86.9%\n",
      "method clust3:\n",
      "cluster 5, accuracy 83.6%\n",
      "cluster 4, accuracy 86.0%\n",
      "cluster 1, accuracy 85.0%\n",
      "cluster 2, accuracy 93.4%\n",
      "cluster 3, accuracy 90.5%\n",
      "average accuracy on clusters 87.7%\n"
     ]
    }
   ],
   "source": [
    "#print(f\"F1 on full dataset : {100*score_rf['f1_macro']:0.1f}%\")\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']}, accuracy {100*score_cluster['metrics']['accuracy']:0.1f}%\")  \n",
    "        average_score = average_score + score_cluster['metrics']['accuracy']\n",
    "    average_score = average_score / (i+1)\n",
    "    print(f\"average accuracy on clusters {100*average_score:0.1f}%\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
