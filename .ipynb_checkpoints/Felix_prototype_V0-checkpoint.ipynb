{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Felix prototype\n",
    "**Version 0**   \n",
    "**Date 21/10/2018**  \n",
    "  \n",
    "Model used : **Random Forest** Classifier on features selected through **lasso**  \n",
    "Clustering method used : **Hierarchical clustering** using **ward metric** based on 6 **NOT variable** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_project = Path.home() / Path('Google Drive/Felix')\n",
    "path_data = path_project / Path(\"data\")\n",
    "path_dump = path_project / Path(\"dump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "file = path_data / Path(\"dataset.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    dataset = pd.read_csv(fp,  encoding='utf-8',low_memory=False, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features scope and selection strategy  \n",
    "Features are selected using lasso on the full scope of feature.\n",
    "The 50 more important features (logistic regression coef ranking) are kept regardless of their activability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load feature sets\n",
    "filename = path_dump / Path(\"dict_features_sets.sav\")\n",
    "with open(filename, 'rb') as fp:\n",
    "     dict_features_sets = pickle.load(fp)\n",
    "\n",
    "usual_common_features = dict_features_sets['usual_common_features']\n",
    "cdv_actionable_individual_1_features = dict_features_sets['cdv_actionable_individual_1_features']\n",
    "cdv_actionable_individual_2_features = dict_features_sets['cdv_actionable_individual_2_features']\n",
    "RFE_LogisticRegression_50_features = dict_features_sets['RFE_LogisticRegression_50_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 50 most important features obtained using lasso:\n",
      "['SITUEMP3_Inactif', 'BANQEPA_Oui', 'CHOIXNUC_Sans avis', 'ETATSAN', 'NIVPERSO', 'UDA10_DOM', 'revtot7', 'INQAGRE3_Non inquiet', 'zau2010_nan', 'INQCHOM3_Non inquiet', 'NOT_LIBR', 'RE_LOG_Oui', 'LIEN_2_Conjoint ou compagnon', 'SOUFFINS_Oui', 'PCSENQ10_Ouvrier', 'NB03_2_Oui, enfant de moins de 3 ans', 'NOT_PROF', 'RE_VOIT_Oui', 'INQMALAD', 'CHERCHEM_Oui', 'TRAVFEM_Elles devraient travailler quand elles le désirent', 'SOUFFNER_Oui', 'HANDICAP_Oui', 'SITUFAM_Couple sans enfants', 'PREOTENS_Oui', 'INQALIM', 'SOUFFDEP_Oui', 'CLASSESO_Les défavorisés', 'RE_MEDI_Oui', 'OPIRSA_[Nsp]', 'CONFENTR', 'CLASSESO_La classe populaire', 'NOT_FAMI', 'VACANCES_Oui', 'RE_ALIM_nan', 'SECURITE', 'RE_EQUI_[Nsp]', 'CADVIE', 'STATMAT4_En ménage, marié', 'RE_ALIM_Oui', 'NBENF6', 'CLASSESO_La classe moyenne supérieure', 'NBCHOM', 'CDV5', 'PROGRAD_nan', 'ASSO10_2_Non adhérent', 'OPIIMMIG_[Nsp]', 'RE_VAC_nan', 'INQCHOMA', 'NOT_AMIS']\n"
     ]
    }
   ],
   "source": [
    "print(\"The 50 most important features obtained using lasso:\")\n",
    "print(list(RFE_LogisticRegression_50_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering method - feature used \n",
    "Hierarchical clustering is used using 6 common \"NOT_\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading clustering\n",
    "file = path_data / Path(\"clustTest3.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    clustTest1 = pd.read_csv(fp,  encoding='utf-8',low_memory=False, sep=\";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set and test set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number exemple: 10788\n",
      "- training set: 1600\n",
      "- test set: 400\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n"
     ]
    }
   ],
   "source": [
    "df = dataset.loc[:,:]\n",
    "# reducing problem to a 2 class classification problem\n",
    "df[\"HEUREUX_CLF\"] = 0\n",
    "df.loc[df[\"HEUREUX\"]==4, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==3, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==5, \"HEUREUX_CLF\"] = None\n",
    "\n",
    "scope = ( RFE_LogisticRegression_50_features  )  & set(dataset.columns)\n",
    "n_max = 2000\n",
    "\n",
    "df = df.loc[:,scope | {\"HEUREUX_CLF\"} ].dropna()\n",
    "features = df.loc[:,scope ].columns\n",
    "\n",
    "X = df.loc[:,scope]\n",
    "y = df[\"HEUREUX_CLF\"]\n",
    "\n",
    "\n",
    "Xs, ys = resample(X, y, random_state=42)\n",
    "\n",
    "Xs = Xs.iloc[0:n_max,:]\n",
    "ys = ys.iloc[0:n_max]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Number exemple: {y.shape[0]}\\n- training set: \\\n",
    "{y_train.shape[0]}\\n- test set: {y_test.shape[0]}\")\n",
    "print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "print(f\"Number of class: {len(np.unique(y))}\")\n",
    "for c in np.unique(y):\n",
    "    print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and model performance evaluation on full dataset (before clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determination of optimal hyperparameters in 45.5 s\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "Accuracy Score of cross valdation 75.75%\n",
      "Random Forest, p=50\n",
      "Model score\n",
      "- Accuracy : 73.5 %\n",
      "- Precision : 73.8 % (Happy # positive class)\n",
      "- Recall : 90.1 %\n",
      "- F1 score : 81.1 %\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "n_estimators_range = [32,64,128,256,512]\n",
    "max_depth_range = [4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32,\n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced'}\n",
    "clf = RandomForestClassifier(**params)\n",
    "\n",
    "grid = GridSearchCV(clf, scoring='accuracy', param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Determination of optimal hyperparameters in {time.time() - startTime:0.1f} s\")\n",
    "print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "Accuracy Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "\n",
    "# Learning on full training set with optimals hyperparameters and score on test set\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "          'n_estimators' : grid.best_params_['n_estimators'],\n",
    "          'max_depth' : grid.best_params_['max_depth']}\n",
    "clf = RandomForestClassifier(**params).fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"Random Forest, p={X_train.shape[1]}\")\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")\n",
    "res_full  = {\n",
    "    'f1_score' : f1,\n",
    "    'accuracy' : accuracy,\n",
    "    'precision' : p,\n",
    "    'recall' : r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 6 -revtot7- (0.054328)\n",
      "\tActionable at individual level (2)\n",
      "2. feature 16 -NOT_PROF- (0.045580)\n",
      "\tActionable at individual level (1)\n",
      "3. feature 17 -NOT_AMIS- (0.043476)\n",
      "\tActionable at individual level (1)\n",
      "4. feature 4 -NIVPERSO- (0.037692)\n",
      "\tActionable at individual level (2)\n",
      "5. feature 41 -NBENF6- (0.036162)\n",
      "\tActionable at individual level (2)\n",
      "6. feature 10 -NOT_LIBR- (0.035938)\n",
      "\tActionable at individual level (1)\n",
      "7. feature 27 -SOUFFDEP_Oui- (0.035848)\n",
      "\tActionable at individual level (2)\n",
      "8. feature 33 -NOT_FAMI- (0.034886)\n",
      "\tActionable at individual level (1)\n",
      "9. feature 3 -ETATSAN- (0.034406)\n",
      "\tActionable at individual level (1)\n",
      "10. feature 38 -CADVIE- (0.034308)\n",
      "\tActionable at individual level (1)\n",
      "11. feature 26 -INQALIM- (0.033096)\n",
      "\tActionable at individual level (1)\n",
      "12. feature 31 -CONFENTR- (0.032741)\n",
      "\tActionable at individual level (1)\n",
      "13. feature 43 -CDV5- (0.032478)\n",
      "\tActionable at individual level (2)\n",
      "14. feature 48 -INQCHOMA- (0.030695)\n",
      "\tActionable at individual level (1)\n",
      "15. feature 36 -SECURITE- (0.028384)\n",
      "\tActionable at individual level (2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1192cda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features_name = np.array(features)\n",
    "#features_name_sorted_rf = features_name[indices]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "max_features = 15\n",
    "\n",
    "for f in range(min(X.shape[1],max_features)):\n",
    "    print(\"%d. feature %d -%s- (%f)\" % (f + 1, indices[f],features_name[indices[f]], importances[indices[f]]))\n",
    "    if features_name[indices[f]] in cdv_actionable_individual_1_features:\n",
    "        print(\"\\tActionable at individual level (1)\")\n",
    "    elif features_name[indices[f]] in cdv_actionable_individual_2_features:\n",
    "        print(\"\\tActionable at individual level (2)\")\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and model performance evaluation on each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators_range = [16,32,64,128]\n",
    "max_depth_range = [2,4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "params = {'max_features' :'sqrt', \n",
    "          'random_state' : 32, \n",
    "          'min_samples_split' : 2, \n",
    "          'class_weight' : 'balanced'\n",
    "         }\n",
    "scope = ( RFE_LogisticRegression_50_features )  & set(dataset.columns)\n",
    "features = df.loc[:,scope].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust3\n",
      "liste of clusters : [2 4 6 1 3 5]\n",
      "cluster 2 : 3053 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 32} \n",
      "cross validation score 80.19%\n",
      "\n",
      "cluster 4 : 2359 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "cross validation score 83.88%\n",
      "\n",
      "cluster 6 : 2313 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 64} \n",
      "cross validation score 82.69%\n",
      "\n",
      "cluster 1 : 528 elements\n",
      "Number exemple: 505\n",
      "        - training set: 404\n",
      "        - test set: 101\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 128} \n",
      "cross validation score 84.16%\n",
      "\n",
      "cluster 3 : 1384 elements\n",
      "Number exemple: 1367\n",
      "        - training set: 1093\n",
      "        - test set: 274\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "cross validation score 86.18%\n",
      "\n",
      "cluster 5 : 1494 elements\n",
      "Number exemple: 1472\n",
      "        - training set: 1177\n",
      "        - test set: 295\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "cross validation score 84.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_clustering_methods = []\n",
    "clustering_methods = clustTest1.columns[2:3]\n",
    "\n",
    "for method in clustering_methods:\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"\\nAnalysis cluster method {method}\")\n",
    "    cluster_list = clustTest1[method].unique()\n",
    "    print(f\"liste of clusters : {cluster_list}\")\n",
    "    score_cluster = []\n",
    "    for cluster in cluster_list:\n",
    "        index_scope = clustTest1.loc[clustTest1[method]==cluster,:].index\n",
    "        print(f\"cluster {cluster} : {len(index_scope)} elements\")\n",
    "        \n",
    "        Xc = X.loc[index_scope.intersection(X.index),:]\n",
    "        yc = y[index_scope.intersection(X.index)]\n",
    "        \n",
    "        Xs, ys = resample(Xc, yc, random_state=42)\n",
    "        \n",
    "        Xs = Xs.iloc[0:n_max,:]\n",
    "        ys = ys.iloc[0:n_max]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(Xs, ys,\n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=42)\n",
    "\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "                \n",
    "        print(f\"Number exemple: {ys.shape[0]}\\n\\\n",
    "        - training set: {y_train.shape[0]}\\n\\\n",
    "        - test set: {y_test.shape[0]}\")\n",
    "        print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "        print(f\"Number of class: {len(np.unique(y))}\")\n",
    "        for c in np.unique(y):\n",
    "            print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")\n",
    "            \n",
    "            \n",
    "        startTime = time.time()\n",
    "        clf = RandomForestClassifier(**params)\n",
    "        grid = GridSearchCV(clf, \n",
    "                            scoring='accuracy', \n",
    "                            param_grid=param_grid)\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "cross validation score {100*grid.best_score_:0.2f}%\")\n",
    "        print()\n",
    "\n",
    "        # Learning on full training set with optimals hyperparameters and score on test set\n",
    "        params_opt = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "                      'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "                      'n_estimators' : grid.best_params_['n_estimators'],\n",
    "                      'max_depth' : grid.best_params_['max_depth']}\n",
    "        clf = RandomForestClassifier(**params_opt).fit(X_train, y_train)\n",
    "\n",
    "            \n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        f1 = f1_score(y_test, y_test_pred)\n",
    "        p = precision_score(y_test, y_test_pred)\n",
    "        r = recall_score(y_test, y_test_pred)            \n",
    "\n",
    "        res  = {'f1_score' : f1,\n",
    "                'accuracy' : accuracy,\n",
    "                'precision' : p,\n",
    "                'recall' : r}\n",
    "            \n",
    "        cl = {'cluster' : cluster,\n",
    "              'size' : len(index_scope),\n",
    "              'model' : 'RandomForestClassifier',\n",
    "              'params' : params_opt,\n",
    "              'metrics' : res\n",
    "             }\n",
    "         \n",
    "        score_cluster.append(cl)\n",
    "        \n",
    "    d = {'clustering_method' : method,\n",
    "         'cluster_scores' : score_cluster\n",
    "        }\n",
    "    score_clustering_methods.append(d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance gain obtained using clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method clust3:\n",
      "cluster 2 (3053), f1 macro 90.7%\n",
      "cluster 4 (2359), f1 macro 93.1%\n",
      "cluster 6 (2313), f1 macro 93.5%\n",
      "cluster 1 (528), f1 macro 86.0%\n",
      "cluster 3 (1384), f1 macro 92.5%\n",
      "cluster 5 (1494), f1 macro 90.4%\n",
      "average f1 on clusters 91.7% gain 10.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    total_size = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']} ({score_cluster['size']}), f1 macro {100*score_cluster['metrics']['f1_score']:0.1f}%\")  \n",
    "        average_score += score_cluster['metrics']['f1_score']*score_cluster['size']\n",
    "        total_size += score_cluster['size']\n",
    "        \n",
    "    average_score = average_score / total_size\n",
    "    print(f\"average f1 on clusters {100*average_score:0.1f}% gain {100*(average_score-res_full['f1_score']):0.1f}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method clust3:\n",
      "cluster 2 (3053) , accuracy 86.8%\n",
      "cluster 4 (2359) , accuracy 89.8%\n",
      "cluster 6 (2313) , accuracy 90.5%\n",
      "cluster 1 (528) , accuracy 87.1%\n",
      "cluster 3 (1384) , accuracy 89.1%\n",
      "cluster 5 (1494) , accuracy 88.5%\n",
      "average accuracy on clusters 88.7% gain 15.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    total_size = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']} ({score_cluster['size']}) , accuracy {100*score_cluster['metrics']['accuracy']:0.1f}%\")  \n",
    "        average_score = average_score + score_cluster['metrics']['accuracy']*score_cluster['size']\n",
    "        total_size += score_cluster['size']\n",
    "    average_score = average_score / total_size\n",
    "    print(f\"average accuracy on clusters {100*average_score:0.1f}% gain {100*(average_score-res_full['accuracy']):0.1f}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature importance of the models & actionable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
