{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#%pylab inline\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_project = Path.home() / Path('Google Drive/Felix')\n",
    "path_data = path_project / Path(\"data\")\n",
    "path_dump = path_project / Path(\"dump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading cdv data\n",
    "file = path_data / Path(\"felix.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    cdv = pd.read_csv(fp,  encoding='cp1252',low_memory=False, index_col = 0)\n",
    "# loadind cdv data without format\n",
    "file = path_data / Path(\"felix_ssfmt.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    cdv_ssfmt = pd.read_csv(fp,  encoding='cp1252',low_memory=False, index_col = 0)\n",
    "    # loading MergeCommunesEnvi data\n",
    "file = path_data / Path(\"MergeCommunesEnvi.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    MergeCommunesEnvi = pd.read_csv(fp,  encoding='cp1252',low_memory=False, sep=';', index_col = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load various variable set\n",
    "filename = path_dump / Path(\"dict_var_groups.sav\")\n",
    "with open(filename, 'rb') as fp:\n",
    "     dict_var_groups = pickle.load(fp)\n",
    "\n",
    "usual_common_scope = dict_var_groups['usual_common_scope']\n",
    "\n",
    "cat_var = dict_var_groups['cat_var']\n",
    "cat_max9_var = dict_var_groups['cat_max9_var']\n",
    "quant_var = dict_var_groups['quant_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final number of variable kept : 419\n"
     ]
    }
   ],
   "source": [
    "df = MergeCommunesEnvi.loc[:,:]\n",
    "df.loc[:,cdv_ssfmt.columns] = cdv_ssfmt.loc[:,:]\n",
    "df = df.loc[:,usual_common_scope]\n",
    "df.loc[:,(cat_var & usual_common_scope) - {\"HEUREUX\"}] = cdv.loc[:,(cat_var & usual_common_scope) - {\"HEUREUX\"}]\n",
    "print(f\"\\nFinal number of variable kept : {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419 columns out of which 155 are corresponding to categorial features\n"
     ]
    }
   ],
   "source": [
    "p = df.shape[1]\n",
    "print(f\"{p} columns out of which {len((cat_var & usual_common_scope))-1} \\\n",
    "are corresponding to categorial features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 columns after encoding of 155 categorial variables in 572 binary variables (K-1 one hot encoding)\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, \n",
    "                    columns=(cat_var & usual_common_scope) - {\"HEUREUX\"},\n",
    "                    dummy_na = True,\n",
    "                    drop_first=1)\n",
    "\n",
    "q = df.shape[1]\n",
    "print(f\"{q} columns after encoding of {len((cat_var & usual_common_scope))-1} categorial \\\n",
    "variables in {len((cat_var & usual_common_scope))-1+q-p} binary variables \\\n",
    "(K-1 one hot encoding)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding of \"HEUREUX\" '[nsp]'\n",
    "df.loc[df[\"HEUREUX\"]==5,\"HEUREUX\"]= None\n",
    "df = df.loc[np.isfinite(df['HEUREUX']).index,:]\n",
    "\n",
    "\n",
    "# treating remaining missing values\n",
    "features = df.columns.drop(['HEUREUX'])\n",
    "df_tmp = df.loc[:,set(features) | {\"HEUREUX\"}].dropna()\n",
    "\n",
    "X = df_tmp.loc[:,features]\n",
    "y = df_tmp[\"HEUREUX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balanced_subsample(x,y,subsample_size=1.0):\n",
    "\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            this_xs = this_xs.reindex(np.random.permutation(this_xs.index))\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "    \n",
    "    xs = pd.concat(xs)\n",
    "    ys = pd.Series(data=np.concatenate(ys),name='target')\n",
    "\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size :1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "n = y.shape[0]\n",
    "nb_value = 20 # Nombre de valeurs testées pour l'hyperparamètre\n",
    "mean_score_l1 = np.zeros(nb_value)\n",
    "C_log = np.logspace(-2,2,nb_value)\n",
    "cv = 6 # V-fold, nombre de fold\n",
    "scoring='f1_macro'\n",
    "\n",
    "score = np.empty(len(range(10,110,10)))\n",
    "\n",
    "np.random.seed(seed=42) \n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "\n",
    "for j, size in enumerate(range(10,110,10)):\n",
    "    m = int(n*size/100)\n",
    "    print(f\"size :{m}\")\n",
    "    Xs, ys = resample(X, y)\n",
    "    Xs = Xs.iloc[0:m,:]\n",
    "    ys = ys.iloc[0:m]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xs, \n",
    "                                                    ys, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    mean_score_l1 = np.empty(nb_value)\n",
    "    \n",
    "    for i, C in enumerate(C_log):\n",
    "        clf = LogisticRegression(C=C, penalty='l1', \n",
    "                                 random_state=42, \n",
    "                                 class_weight='balanced')\n",
    "        mean_score_l1[i] = 100*np.mean(1-cross_val_score(clf, \n",
    "                                                     X_train, \n",
    "                                                     y_train,\n",
    "                                                     cv=cv, \n",
    "                                                     scoring=scoring))\n",
    "\n",
    "        \n",
    "    # Learning on full training set with optimals hyperparameters and score on test set\n",
    "    clf = LogisticRegression(C=C_log[np.argmax(mean_score_l1)], \n",
    "                                 penalty='l1', \n",
    "                                 random_state=42, \n",
    "                                 class_weight='balanced')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    score[i] = f1_score(y_test, y_test_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(range(10,110,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_value = 20 # Nombre de valeurs testées pour l'hyperparamètre\n",
    "mean_score_l1 = np.zeros(nb_value)\n",
    "C_log = np.logspace(-2,2,nb_value)\n",
    "cv = 6 # V-fold, nombre de fold\n",
    "\n",
    "mean_score_l1 = np.empty(nb_value)\n",
    "std_scores_l1 = np.empty(nb_value)\n",
    "\n",
    "np.random.seed(seed=42) \n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "for i, C in enumerate(C_log):\n",
    "    clf = LogisticRegression(C=C, penalty='l1', \n",
    "                             tol=0.01, random_state=42, \n",
    "                             class_weight='balanced')\n",
    "    mean_score_l1[i] = 100*np.mean(1-cross_val_score(clf, \n",
    "                                                     X_train, \n",
    "                                                     y_train,\n",
    "                                                     cv=cv, \n",
    "                                                     scoring='accuracy'))\n",
    "    std_scores_l1[i] = 100*np.std(1-cross_val_score(clf, \n",
    "                                                    X_train, \n",
    "                                                    y_train, \n",
    "                                                    cv=cv, \n",
    "                                                    scoring='accuracy'))    \n",
    "\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.semilogx(C_log,mean_score_l1[:],'r',linewidth=2,label='moyenne (l1)')\n",
    "plt.semilogx(C_log,mean_score_l1[:]-0.5*std_scores_l1[:],\n",
    "             'r--', label=u'+/-0.5 écart type')\n",
    "plt.semilogx(C_log,mean_score_l1[:]+0.5*std_scores_l1[:],'r--')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Valeur de pénalisation C = 1/lambda\")\n",
    "plt.ylabel(u\"Erreur de validation croisée (%)\\n(Taux moyen d'erreur de classification)\")\n",
    "plt.title(u\"Choix de l'hyperparamètre C\\npar validation croisée \\\n",
    "(V-fold avec V = %s)\" % (cv)) \n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(\"Détermination des paramètres optimaux en %0.1f s\" % (time.time() - startTime))\n",
    "print(\"Pénalisation l1, valeur optimale : C = %0.2f\" % (C_log[np.argmin(mean_score_l1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning on full training set with optimals hyperparameters \n",
    "# and score evaluation on test set\n",
    "clf = LogisticRegression(C=C_log[np.argmin(mean_score_l1)], \n",
    "                         penalty='l1', \n",
    "                         tol=0.01, \n",
    "                         random_state=42, \n",
    "                         class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
