{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering evaluation\n",
    "Script to evaluate clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "#from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.preprocessing import LabelBinarizer\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.feature_selection import RFECV, RFE, SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_project = Path.home() / Path('Google Drive/Felix')\n",
    "path_data = path_project / Path(\"data\")\n",
    "path_dump = path_project / Path(\"dump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "file = path_data / Path(\"dataset.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    dataset = pd.read_csv(fp,  encoding='utf-8',low_memory=False, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load feature sets\n",
    "filename = path_dump / Path(\"dict_features_sets.sav\")\n",
    "with open(filename, 'rb') as fp:\n",
    "     dict_features_sets = pickle.load(fp)\n",
    "\n",
    "usual_common_features = dict_features_sets['usual_common_features']\n",
    "indiv_act_features = dict_features_sets['indiv_act_features']\n",
    "indiv_semi_act_features = dict_features_sets['indiv_semi_act_features']\n",
    "RFE_LogisticRegression_20_features = dict_features_sets['RFE_LogisticRegression_20_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading clustering\n",
    "file = path_data / Path(\"clustTest3.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    clustTest1 = pd.read_csv(fp,  encoding='utf-8',low_memory=False, sep=\";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clust1</th>\n",
       "      <th>clust2</th>\n",
       "      <th>clust3</th>\n",
       "      <th>clust4</th>\n",
       "      <th>clust5</th>\n",
       "      <th>clust6</th>\n",
       "      <th>clust7</th>\n",
       "      <th>clust8</th>\n",
       "      <th>clust9</th>\n",
       "      <th>clust10</th>\n",
       "      <th>clust11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTER6</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373001</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373002</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373004</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373005</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        clust1  clust2  clust3  clust4  clust5  clust6  clust7  clust8  \\\n",
       "INTER6                                                                   \n",
       "373001       1       1       2       3       3       5       3       4   \n",
       "373002       1       1       2       1       4       2       1       4   \n",
       "373003       1       1       4       1       4       4       2       4   \n",
       "373004       1       1       2       1       4       4       2       4   \n",
       "373005       1       1       2       2       4       3       1       4   \n",
       "\n",
       "        clust9  clust10  clust11  \n",
       "INTER6                            \n",
       "373001       1        4        5  \n",
       "373002       5        3        1  \n",
       "373003       3        2        1  \n",
       "373004       1        3        3  \n",
       "373005       3        3        4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustTest1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number exemple: 10674\n",
      "- training set: 1600\n",
      "- test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n"
     ]
    }
   ],
   "source": [
    "df = dataset.loc[:,:]\n",
    "# reducing problem to a 2 class classification problem\n",
    "df[\"HEUREUX_CLF\"] = 0\n",
    "df.loc[df[\"HEUREUX\"]==4, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==3, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==5, \"HEUREUX_CLF\"] = None\n",
    "\n",
    "scope = ( RFE_LogisticRegression_20_features | indiv_act_features )  & set(dataset.columns)\n",
    "n_max = 2000\n",
    "\n",
    "df = df.loc[:,scope | {\"HEUREUX_CLF\"} ].dropna()\n",
    "features = df.loc[:,scope ].columns\n",
    "\n",
    "X = df.loc[:,scope]\n",
    "y = df[\"HEUREUX_CLF\"]\n",
    "\n",
    "\n",
    "Xs, ys = resample(X, y, random_state=42)\n",
    "\n",
    "Xs = Xs.iloc[0:n_max,:]\n",
    "ys = ys.iloc[0:n_max]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Number exemple: {y.shape[0]}\\n- training set: \\\n",
    "{y_train.shape[0]}\\n- test set: {y_test.shape[0]}\")\n",
    "print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "print(f\"Number of class: {len(np.unique(y))}\")\n",
    "for c in np.unique(y):\n",
    "    print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determination of optimal hyperparameters in 44.5 s\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "Accuracy Score of cross valdation 75.44%\n",
      "Random Forest, p=66\n",
      "Model score\n",
      "- Accuracy : 78.5 %\n",
      "- Precision : 80.2 % (Happy # positive class)\n",
      "- Recall : 88.8 %\n",
      "- F1 score : 84.3 %\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "n_estimators_range = [32,64,128,256,512]\n",
    "max_depth_range = [4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32,\n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced'}\n",
    "clf = RandomForestClassifier(**params)\n",
    "\n",
    "grid = GridSearchCV(clf, scoring='accuracy', param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Determination of optimal hyperparameters in {time.time() - startTime:0.1f} s\")\n",
    "print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "Accuracy Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "\n",
    "# Learning on full training set with optimals hyperparameters and score on test set\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "          'n_estimators' : grid.best_params_['n_estimators'],\n",
    "          'max_depth' : grid.best_params_['max_depth']}\n",
    "clf = RandomForestClassifier(**params).fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"Random Forest, p={X_train.shape[1]}\")\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")\n",
    "res_full  = {\n",
    "    'f1_score' : f1,\n",
    "    'accuracy' : accuracy,\n",
    "    'precision' : p,\n",
    "    'recall' : r\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation on each clusters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators_range = [16,32,64,128]\n",
    "max_depth_range = [2,4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "params = {'max_features' :'sqrt', \n",
    "          'random_state' : 32, \n",
    "          'min_samples_split' : 2, \n",
    "          'class_weight' : 'balanced'\n",
    "         }\n",
    "scope = ( RFE_LogisticRegression_20_features | indiv_act_features )  & set(dataset.columns)\n",
    "features = df.loc[:,scope].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust1\n",
      "liste of clusters : [1 2 3 4]\n",
      "++++++++++++\n",
      "cluster 1 : 8416 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 76.69%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 470 elements\n",
      "Number exemple: 422\n",
      "        - training set: 337\n",
      "        - test set: 85\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 128} \n",
      "        Score of cross valdation 83.09%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 1982 elements\n",
      "Number exemple: 1935\n",
      "        - training set: 1548\n",
      "        - test set: 387\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 86.24%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 263 elements\n",
      "Number exemple: 243\n",
      "        - training set: 194\n",
      "        - test set: 49\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 64} \n",
      "        Score of cross valdation 79.90%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust2\n",
      "liste of clusters : [1 2 3 4 5 6 7]\n",
      "++++++++++++\n",
      "cluster 1 : 7186 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 77.25%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 337 elements\n",
      "Number exemple: 299\n",
      "        - training set: 239\n",
      "        - test set: 60\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 16} \n",
      "        Score of cross valdation 78.66%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 1982 elements\n",
      "Number exemple: 1935\n",
      "        - training set: 1548\n",
      "        - test set: 387\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 86.24%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 1230 elements\n",
      "Number exemple: 1205\n",
      "        - training set: 964\n",
      "        - test set: 241\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 84.65%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 100 elements\n",
      "Number exemple: 92\n",
      "        - training set: 73\n",
      "        - test set: 19\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 64} \n",
      "        Score of cross valdation 76.71%\n",
      "\n",
      "++++++++++++\n",
      "cluster 6 : 133 elements\n",
      "Number exemple: 123\n",
      "        - training set: 98\n",
      "        - test set: 25\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 16} \n",
      "        Score of cross valdation 91.84%\n",
      "\n",
      "++++++++++++\n",
      "cluster 7 : 163 elements\n",
      "Number exemple: 151\n",
      "        - training set: 120\n",
      "        - test set: 31\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 16} \n",
      "        Score of cross valdation 85.83%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust3\n",
      "liste of clusters : [2 4 6 1 3 5]\n",
      "++++++++++++\n",
      "cluster 2 : 3053 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 81.38%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 2359 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 85.38%\n",
      "\n",
      "++++++++++++\n",
      "cluster 6 : 2313 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 84.50%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 528 elements\n",
      "Number exemple: 472\n",
      "        - training set: 377\n",
      "        - test set: 95\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 77.45%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 1384 elements\n",
      "Number exemple: 1355\n",
      "        - training set: 1084\n",
      "        - test set: 271\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 32} \n",
      "        Score of cross valdation 87.36%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 1494 elements\n",
      "Number exemple: 1461\n",
      "        - training set: 1168\n",
      "        - test set: 293\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 81.76%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust4\n",
      "liste of clusters : [3 1 2 6 5 4 7]\n",
      "++++++++++++\n",
      "cluster 3 : 818 elements\n",
      "Number exemple: 748\n",
      "        - training set: 598\n",
      "        - test set: 150\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 82.94%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 4494 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 64} \n",
      "        Score of cross valdation 78.81%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 1735 elements\n",
      "Number exemple: 1680\n",
      "        - training set: 1344\n",
      "        - test set: 336\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 85.27%\n",
      "\n",
      "++++++++++++\n",
      "cluster 6 : 1012 elements\n",
      "Number exemple: 983\n",
      "        - training set: 786\n",
      "        - test set: 197\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 16} \n",
      "        Score of cross valdation 85.88%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 1059 elements\n",
      "Number exemple: 1034\n",
      "        - training set: 827\n",
      "        - test set: 207\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 83.56%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 1477 elements\n",
      "Number exemple: 1441\n",
      "        - training set: 1152\n",
      "        - test set: 289\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 64} \n",
      "        Score of cross valdation 85.24%\n",
      "\n",
      "++++++++++++\n",
      "cluster 7 : 536 elements\n",
      "Number exemple: 526\n",
      "        - training set: 420\n",
      "        - test set: 106\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 16} \n",
      "        Score of cross valdation 83.81%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust5\n",
      "liste of clusters : [3 4 1 2 5]\n",
      "++++++++++++\n",
      "cluster 3 : 1313 elements\n",
      "Number exemple: 1277\n",
      "        - training set: 1021\n",
      "        - test set: 256\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 32} \n",
      "        Score of cross valdation 86.58%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 3917 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 79.69%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 5055 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 78.25%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 725 elements\n",
      "Number exemple: 692\n",
      "        - training set: 553\n",
      "        - test set: 139\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 64} \n",
      "        Score of cross valdation 81.56%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 121 elements\n",
      "Number exemple: 46\n",
      "        - training set: 36\n",
      "        - test set: 10\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 16} \n",
      "        Score of cross valdation 86.11%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust6\n",
      "liste of clusters : [5 2 4 3 1 6]\n",
      "++++++++++++\n",
      "cluster 5 : 731 elements\n",
      "Number exemple: 687\n",
      "        - training set: 549\n",
      "        - test set: 138\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "        Score of cross valdation 82.70%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 3408 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 64} \n",
      "        Score of cross valdation 80.75%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 2761 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 32} \n",
      "        Score of cross valdation 83.69%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 1886 elements\n",
      "Number exemple: 1818\n",
      "        - training set: 1454\n",
      "        - test set: 364\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 64} \n",
      "        Score of cross valdation 83.43%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 2200 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 83.31%\n",
      "\n",
      "++++++++++++\n",
      "cluster 6 : 145 elements\n",
      "Number exemple: 57\n",
      "        - training set: 45\n",
      "        - test set: 12\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 2, 'n_estimators': 64} \n",
      "        Score of cross valdation 82.22%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust7\n",
      "liste of clusters : [3 1 2 4]\n",
      "++++++++++++\n",
      "cluster 3 : 2566 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 80.44%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 2203 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 32} \n",
      "        Score of cross valdation 85.56%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 6183 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 16} \n",
      "        Score of cross valdation 79.06%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 179 elements\n",
      "Number exemple: 74\n",
      "        - training set: 59\n",
      "        - test set: 15\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 2, 'n_estimators': 16} \n",
      "        Score of cross valdation 79.66%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust8\n",
      "liste of clusters : [4 2 3 1 5]\n",
      "++++++++++++\n",
      "cluster 4 : 4600 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 64} \n",
      "        Score of cross valdation 79.25%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 274 elements\n",
      "Number exemple: 264\n",
      "        - training set: 211\n",
      "        - test set: 53\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 32} \n",
      "        Score of cross valdation 85.31%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 1719 elements\n",
      "Number exemple: 1641\n",
      "        - training set: 1312\n",
      "        - test set: 329\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 81.10%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 4443 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 64} \n",
      "        Score of cross valdation 80.12%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 95 elements\n",
      "Number exemple: 70\n",
      "        - training set: 56\n",
      "        - test set: 14\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 8, 'n_estimators': 16} \n",
      "        Score of cross valdation 89.29%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust9\n",
      "liste of clusters : [1 5 3 4 2]\n",
      "++++++++++++\n",
      "cluster 1 : 3533 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 32} \n",
      "        Score of cross valdation 80.12%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 1521 elements\n",
      "Number exemple: 1463\n",
      "        - training set: 1170\n",
      "        - test set: 293\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 32} \n",
      "        Score of cross valdation 85.73%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 3271 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 82.44%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 2683 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 64} \n",
      "        Score of cross valdation 83.38%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 123 elements\n",
      "Number exemple: 91\n",
      "        - training set: 72\n",
      "        - test set: 19\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 4, 'n_estimators': 128} \n",
      "        Score of cross valdation 73.61%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust10\n",
      "liste of clusters : [4 3 2 1 5]\n",
      "++++++++++++\n",
      "cluster 4 : 1452 elements\n",
      "Number exemple: 1404\n",
      "        - training set: 1123\n",
      "        - test set: 281\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 128} \n",
      "        Score of cross valdation 84.59%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 5920 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 77.19%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 2158 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 32} \n",
      "        Score of cross valdation 80.81%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 1439 elements\n",
      "Number exemple: 1394\n",
      "        - training set: 1115\n",
      "        - test set: 279\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "        Score of cross valdation 83.14%\n",
      "\n",
      "++++++++++++\n",
      "cluster 5 : 162 elements\n",
      "Number exemple: 62\n",
      "        - training set: 49\n",
      "        - test set: 13\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values are {'max_depth': 4, 'n_estimators': 128} \n",
      "        Score of cross valdation 81.63%\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust11\n",
      "liste of clusters : [5 1 3 4 2 6 7]\n",
      "++++++++++++\n",
      "cluster 5 : 1231 elements\n",
      "Number exemple: 1188\n",
      "        - training set: 950\n",
      "        - test set: 238\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 32} \n",
      "        Score of cross valdation 83.68%\n",
      "\n",
      "++++++++++++\n",
      "cluster 1 : 2753 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 16} \n",
      "        Score of cross valdation 83.44%\n",
      "\n",
      "++++++++++++\n",
      "cluster 3 : 2344 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 32} \n",
      "        Score of cross valdation 84.69%\n",
      "\n",
      "++++++++++++\n",
      "cluster 4 : 1504 elements\n",
      "Number exemple: 1456\n",
      "        - training set: 1164\n",
      "        - test set: 292\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 83.25%\n",
      "\n",
      "++++++++++++\n",
      "cluster 2 : 3105 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "        Score of cross valdation 79.81%\n",
      "\n",
      "++++++++++++\n",
      "cluster 6 : 130 elements\n",
      "Number exemple: 74\n",
      "        - training set: 59\n",
      "        - test set: 15\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 16} \n",
      "        Score of cross valdation 89.83%\n",
      "\n",
      "++++++++++++\n",
      "cluster 7 : 64 elements\n",
      "Number exemple: 5\n",
      "        - training set: 4\n",
      "        - test set: 1\n",
      "Number of features: p=66\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values are {'max_depth': 2, 'n_estimators': 16} \n",
      "        Score of cross valdation 75.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_clustering_methods = []\n",
    "clustering_methods = clustTest1.columns[0:]\n",
    "\n",
    "for method in clustering_methods:\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"\\nAnalysis cluster method {method}\")\n",
    "    cluster_list = clustTest1[method].unique()\n",
    "    print(f\"liste of clusters : {cluster_list}\")\n",
    "    score_cluster = []\n",
    "    for cluster in cluster_list:\n",
    "        index_scope = clustTest1.loc[clustTest1[method]==cluster,:].index\n",
    "        print(\"++++++++++++\")\n",
    "        print(f\"cluster {cluster} : {len(index_scope)} elements\")\n",
    "        \n",
    "        Xc = X.loc[index_scope.intersection(X.index),:]\n",
    "        yc = y[index_scope.intersection(X.index)]\n",
    "        \n",
    "        Xs, ys = resample(Xc, yc, random_state=42)\n",
    "        \n",
    "        Xs = Xs.iloc[0:n_max,:]\n",
    "        ys = ys.iloc[0:n_max]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(Xs, ys,\n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=42)\n",
    "\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "                \n",
    "        print(f\"Number exemple: {ys.shape[0]}\\n\\\n",
    "        - training set: {y_train.shape[0]}\\n\\\n",
    "        - test set: {y_test.shape[0]}\")\n",
    "        print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "        print(f\"Number of class: {len(np.unique(y))}\")\n",
    "        for c in np.unique(y):\n",
    "            print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")\n",
    "            \n",
    "            \n",
    "        startTime = time.time()\n",
    "        clf = RandomForestClassifier(**params)\n",
    "        grid = GridSearchCV(clf, \n",
    "                            scoring='accuracy', \n",
    "                            param_grid=param_grid)\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "        Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "        print()\n",
    "\n",
    "        # Learning on full training set with optimals hyperparameters and score on test set\n",
    "        params_opt = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "                      'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "                      'n_estimators' : grid.best_params_['n_estimators'],\n",
    "                      'max_depth' : grid.best_params_['max_depth']}\n",
    "        clf = RandomForestClassifier(**params_opt).fit(X_train, y_train)\n",
    "\n",
    "            \n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        f1 = f1_score(y_test, y_test_pred)\n",
    "        p = precision_score(y_test, y_test_pred)\n",
    "        r = recall_score(y_test, y_test_pred)            \n",
    "\n",
    "        res  = {'f1_score' : f1,\n",
    "                'accuracy' : accuracy,\n",
    "                'precision' : p,\n",
    "                'recall' : r}\n",
    "            \n",
    "        cl = {'cluster' : cluster,\n",
    "              'size' : len(index_scope),\n",
    "              'model' : 'RandomForestClassifier',\n",
    "              'params' : params_opt,\n",
    "              'metrics' : res\n",
    "             }\n",
    "         \n",
    "        score_cluster.append(cl)\n",
    "        \n",
    "    d = {'clustering_method' : method,\n",
    "         'cluster_scores' : score_cluster\n",
    "        }\n",
    "    score_clustering_methods.append(d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method clust1:\n",
      "cluster 1 (8416), f1 macro 84.9%\n",
      "cluster 2 (470), f1 macro 83.2%\n",
      "cluster 3 (1982), f1 macro 92.3%\n",
      "cluster 4 (263), f1 macro 89.3%\n",
      "average f1 on clusters 86.3% gain 2.0\n",
      "\n",
      "method clust2:\n",
      "cluster 1 (7186), f1 macro 85.2%\n",
      "cluster 2 (337), f1 macro 77.8%\n",
      "cluster 3 (1982), f1 macro 92.3%\n",
      "cluster 4 (1230), f1 macro 87.7%\n",
      "cluster 5 (100), f1 macro 78.3%\n",
      "cluster 6 (133), f1 macro 100.0%\n",
      "cluster 7 (163), f1 macro 94.1%\n",
      "average f1 on clusters 86.8% gain 2.5\n",
      "\n",
      "method clust3:\n",
      "cluster 2 (3053), f1 macro 90.5%\n",
      "cluster 4 (2359), f1 macro 89.1%\n",
      "cluster 6 (2313), f1 macro 90.5%\n",
      "cluster 1 (528), f1 macro 81.3%\n",
      "cluster 3 (1384), f1 macro 91.0%\n",
      "cluster 5 (1494), f1 macro 92.9%\n",
      "average f1 on clusters 90.2% gain 5.9\n",
      "\n",
      "method clust4:\n",
      "cluster 3 (818), f1 macro 83.4%\n",
      "cluster 1 (4494), f1 macro 86.9%\n",
      "cluster 2 (1735), f1 macro 93.6%\n",
      "cluster 6 (1012), f1 macro 92.9%\n",
      "cluster 5 (1059), f1 macro 88.3%\n",
      "cluster 4 (1477), f1 macro 92.6%\n",
      "cluster 7 (536), f1 macro 88.3%\n",
      "average f1 on clusters 89.2% gain 4.9\n",
      "\n",
      "method clust5:\n",
      "cluster 3 (1313), f1 macro 88.1%\n",
      "cluster 4 (3917), f1 macro 87.2%\n",
      "cluster 1 (5055), f1 macro 87.8%\n",
      "cluster 2 (725), f1 macro 86.9%\n",
      "cluster 5 (121), f1 macro 44.4%\n",
      "average f1 on clusters 87.1% gain 2.8\n",
      "\n",
      "method clust6:\n",
      "cluster 5 (731), f1 macro 94.4%\n",
      "cluster 2 (3408), f1 macro 88.8%\n",
      "cluster 4 (2761), f1 macro 90.4%\n",
      "cluster 3 (1886), f1 macro 87.8%\n",
      "cluster 1 (2200), f1 macro 90.5%\n",
      "cluster 6 (145), f1 macro 70.6%\n",
      "average f1 on clusters 89.5% gain 5.2\n",
      "\n",
      "method clust7:\n",
      "cluster 3 (2566), f1 macro 87.6%\n",
      "cluster 1 (2203), f1 macro 94.2%\n",
      "cluster 2 (6183), f1 macro 83.5%\n",
      "cluster 4 (179), f1 macro 85.7%\n",
      "average f1 on clusters 86.6% gain 2.3\n",
      "\n",
      "method clust8:\n",
      "cluster 4 (4600), f1 macro 86.1%\n",
      "cluster 2 (274), f1 macro 73.3%\n",
      "cluster 3 (1719), f1 macro 84.0%\n",
      "cluster 1 (4443), f1 macro 87.8%\n",
      "cluster 5 (95), f1 macro 100.0%\n",
      "average f1 on clusters 86.3% gain 2.0\n",
      "\n",
      "method clust9:\n",
      "cluster 1 (3533), f1 macro 86.3%\n",
      "cluster 5 (1521), f1 macro 88.3%\n",
      "cluster 3 (3271), f1 macro 88.4%\n",
      "cluster 4 (2683), f1 macro 88.8%\n",
      "cluster 2 (123), f1 macro 81.8%\n",
      "average f1 on clusters 87.7% gain 3.4\n",
      "\n",
      "method clust10:\n",
      "cluster 4 (1452), f1 macro 94.6%\n",
      "cluster 3 (5920), f1 macro 88.4%\n",
      "cluster 2 (2158), f1 macro 88.2%\n",
      "cluster 1 (1439), f1 macro 86.8%\n",
      "cluster 5 (162), f1 macro 75.0%\n",
      "average f1 on clusters 88.8% gain 4.5\n",
      "\n",
      "method clust11:\n",
      "cluster 5 (1231), f1 macro 91.8%\n",
      "cluster 1 (2753), f1 macro 91.8%\n",
      "cluster 3 (2344), f1 macro 93.2%\n",
      "cluster 4 (1504), f1 macro 80.8%\n",
      "cluster 2 (3105), f1 macro 85.6%\n",
      "cluster 6 (130), f1 macro 94.7%\n",
      "cluster 7 (64), f1 macro 100.0%\n",
      "average f1 on clusters 89.0% gain 4.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    total_size = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']} ({score_cluster['size']}), f1 macro {100*score_cluster['metrics']['f1_score']:0.1f}%\")  \n",
    "        average_score += score_cluster['metrics']['f1_score']*score_cluster['size']\n",
    "        total_size += score_cluster['size']\n",
    "        \n",
    "    average_score = average_score / total_size\n",
    "    print(f\"average f1 on clusters {100*average_score:0.1f}% gain {100*(average_score-res_full['f1_score']):0.1f}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method clust1:\n",
      "cluster 1 (8416) , accuracy 78.2%\n",
      "cluster 2 (470) , accuracy 80.0%\n",
      "cluster 3 (1982) , accuracy 89.4%\n",
      "cluster 4 (263) , accuracy 87.8%\n",
      "average accuracy on clusters 80.5% gain 2.0\n",
      "\n",
      "method clust2:\n",
      "cluster 1 (7186) , accuracy 78.5%\n",
      "cluster 2 (337) , accuracy 80.0%\n",
      "cluster 3 (1982) , accuracy 89.4%\n",
      "cluster 4 (1230) , accuracy 86.3%\n",
      "cluster 5 (100) , accuracy 73.7%\n",
      "cluster 6 (133) , accuracy 100.0%\n",
      "cluster 7 (163) , accuracy 93.5%\n",
      "average accuracy on clusters 81.8% gain 3.3\n",
      "\n",
      "method clust3:\n",
      "cluster 2 (3053) , accuracy 87.0%\n",
      "cluster 4 (2359) , accuracy 85.0%\n",
      "cluster 6 (2313) , accuracy 86.5%\n",
      "cluster 1 (528) , accuracy 82.1%\n",
      "cluster 3 (1384) , accuracy 88.2%\n",
      "cluster 5 (1494) , accuracy 91.5%\n",
      "average accuracy on clusters 87.0% gain 8.5\n",
      "\n",
      "method clust4:\n",
      "cluster 3 (818) , accuracy 83.3%\n",
      "cluster 1 (4494) , accuracy 81.0%\n",
      "cluster 2 (1735) , accuracy 91.4%\n",
      "cluster 6 (1012) , accuracy 90.4%\n",
      "cluster 5 (1059) , accuracy 85.0%\n",
      "cluster 4 (1477) , accuracy 89.3%\n",
      "cluster 7 (536) , accuracy 84.0%\n",
      "average accuracy on clusters 85.3% gain 6.8\n",
      "\n",
      "method clust5:\n",
      "cluster 3 (1313) , accuracy 84.0%\n",
      "cluster 4 (3917) , accuracy 83.2%\n",
      "cluster 1 (5055) , accuracy 81.2%\n",
      "cluster 2 (725) , accuracy 84.2%\n",
      "cluster 5 (121) , accuracy 50.0%\n",
      "average accuracy on clusters 82.1% gain 3.6\n",
      "\n",
      "method clust6:\n",
      "cluster 5 (731) , accuracy 92.0%\n",
      "cluster 2 (3408) , accuracy 83.8%\n",
      "cluster 4 (2761) , accuracy 84.8%\n",
      "cluster 3 (1886) , accuracy 87.1%\n",
      "cluster 1 (2200) , accuracy 87.2%\n",
      "cluster 6 (145) , accuracy 58.3%\n",
      "average accuracy on clusters 85.5% gain 7.0\n",
      "\n",
      "method clust7:\n",
      "cluster 3 (2566) , accuracy 87.0%\n",
      "cluster 1 (2203) , accuracy 91.0%\n",
      "cluster 2 (6183) , accuracy 77.2%\n",
      "cluster 4 (179) , accuracy 80.0%\n",
      "average accuracy on clusters 82.3% gain 3.8\n",
      "\n",
      "method clust8:\n",
      "cluster 4 (4600) , accuracy 80.0%\n",
      "cluster 2 (274) , accuracy 84.9%\n",
      "cluster 3 (1719) , accuracy 84.2%\n",
      "cluster 1 (4443) , accuracy 81.8%\n",
      "cluster 5 (95) , accuracy 100.0%\n",
      "average accuracy on clusters 81.6% gain 3.1\n",
      "\n",
      "method clust9:\n",
      "cluster 1 (3533) , accuracy 81.5%\n",
      "cluster 5 (1521) , accuracy 85.7%\n",
      "cluster 3 (3271) , accuracy 83.5%\n",
      "cluster 4 (2683) , accuracy 84.2%\n",
      "cluster 2 (123) , accuracy 78.9%\n",
      "average accuracy on clusters 83.3% gain 4.8\n",
      "\n",
      "method clust10:\n",
      "cluster 4 (1452) , accuracy 92.2%\n",
      "cluster 3 (5920) , accuracy 82.0%\n",
      "cluster 2 (2158) , accuracy 86.5%\n",
      "cluster 1 (1439) , accuracy 85.3%\n",
      "cluster 5 (162) , accuracy 69.2%\n",
      "average accuracy on clusters 84.4% gain 5.9\n",
      "\n",
      "method clust11:\n",
      "cluster 5 (1231) , accuracy 89.1%\n",
      "cluster 1 (2753) , accuracy 87.5%\n",
      "cluster 3 (2344) , accuracy 89.2%\n",
      "cluster 4 (1504) , accuracy 86.0%\n",
      "cluster 2 (3105) , accuracy 80.5%\n",
      "cluster 6 (130) , accuracy 93.3%\n",
      "cluster 7 (64) , accuracy 100.0%\n",
      "average accuracy on clusters 86.0% gain 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    total_size = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']} ({score_cluster['size']}) , accuracy {100*score_cluster['metrics']['accuracy']:0.1f}%\")  \n",
    "        average_score = average_score + score_cluster['metrics']['accuracy']*score_cluster['size']\n",
    "        total_size += score_cluster['size']\n",
    "    average_score = average_score / total_size\n",
    "    print(f\"average accuracy on clusters {100*average_score:0.1f}% gain {100*(average_score-res_full['accuracy']):0.1f}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
