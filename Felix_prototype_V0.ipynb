{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Felix prototype\n",
    "**Version 0**   \n",
    "**Date 21/10/2018**  \n",
    "  \n",
    "Model used : **Random Forest** Classifier on features selected through **lasso**  \n",
    "Clustering method used : **Hierarchical clustering** using **ward metric** based on 6 **NOT variable** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_project = Path.home() / Path('Google Drive/Felix')\n",
    "path_data = path_project / Path(\"data\")\n",
    "path_dump = path_project / Path(\"dump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "file = path_data / Path(\"dataset.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    dataset = pd.read_csv(fp,  encoding='utf-8',low_memory=False, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features scope and selection strategy  \n",
    "Features are selected using lasso on the full scope of feature.\n",
    "The 50 more important features (logistic regression coef ranking) are kept regardless of their activability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load feature sets\n",
    "filename = path_dump / Path(\"dict_features_sets.sav\")\n",
    "with open(filename, 'rb') as fp:\n",
    "     dict_features_sets = pickle.load(fp)\n",
    "\n",
    "usual_common_features = dict_features_sets['usual_common_features']\n",
    "cdv_actionable_individual_1_features = dict_features_sets['cdv_actionable_individual_1_features']\n",
    "cdv_actionable_individual_2_features = dict_features_sets['cdv_actionable_individual_2_features']\n",
    "RFE_LogisticRegression_50_features = dict_features_sets['RFE_LogisticRegression_50_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 50 most important features obtained using lasso:\n",
      "['CONFENTR', 'TRAVFEM_Elles devraient travailler quand elles le désirent', 'SOUFFNER_Oui', 'PROGRAD_nan', 'CLASSESO_La classe populaire', 'RE_VAC_nan', 'RE_ALIM_nan', 'PREOTENS_Oui', 'NOT_AMIS', 'SOUFFDEP_Oui', 'VACANCES_Oui', 'ETATSAN', 'UDA10_DOM', 'NB03_2_Oui, enfant de moins de 3 ans', 'NOT_LIBR', 'NOT_PROF', 'CLASSESO_Les défavorisés', 'CHOIXNUC_Sans avis', 'INQAGRE3_Non inquiet', 'revtot7', 'CADVIE', 'INQCHOMA', 'NBENF6', 'RE_MEDI_Oui', 'CLASSESO_La classe moyenne supérieure', 'CDV5', 'RE_LOG_Oui', 'RE_EQUI_[Nsp]', 'INQALIM', 'ASSO10_2_Non adhérent', 'RE_ALIM_Oui', 'INQMALAD', 'INQCHOM3_Non inquiet', 'NIVPERSO', 'SOUFFINS_Oui', 'PCSENQ10_Ouvrier', 'CHERCHEM_Oui', 'NBCHOM', 'RE_VOIT_Oui', 'OPIRSA_[Nsp]', 'BANQEPA_Oui', 'HANDICAP_Oui', 'OPIIMMIG_[Nsp]', 'zau2010_nan', 'LIEN_2_Conjoint ou compagnon', 'SITUEMP3_Inactif', 'NOT_FAMI', 'SECURITE', 'STATMAT4_En ménage, marié', 'SITUFAM_Couple sans enfants']\n"
     ]
    }
   ],
   "source": [
    "print(\"The 50 most important features obtained using lasso:\")\n",
    "print(list(RFE_LogisticRegression_50_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering method - feature used \n",
    "Hierarchical clustering is used using 6 common \"NOT_\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading clustering\n",
    "file = path_data / Path(\"clustTest3.csv\")\n",
    "with Path.open(file, 'rb') as fp:\n",
    "    clustTest1 = pd.read_csv(fp,  encoding='utf-8',low_memory=False, sep=\";\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set and test set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number exemple: 10788\n",
      "- training set: 1600\n",
      "- test set: 400\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n"
     ]
    }
   ],
   "source": [
    "df = dataset.loc[:,:]\n",
    "# reducing problem to a 2 class classification problem\n",
    "df[\"HEUREUX_CLF\"] = 0\n",
    "df.loc[df[\"HEUREUX\"]==4, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==3, \"HEUREUX_CLF\"] = 1\n",
    "df.loc[df[\"HEUREUX\"]==5, \"HEUREUX_CLF\"] = None\n",
    "\n",
    "scope = ( RFE_LogisticRegression_50_features  )  & set(dataset.columns)\n",
    "n_max = 2000\n",
    "\n",
    "df = df.loc[:,scope | {\"HEUREUX_CLF\"} ].dropna()\n",
    "features = df.loc[:,scope ].columns\n",
    "\n",
    "X = df.loc[:,scope]\n",
    "y = df[\"HEUREUX_CLF\"]\n",
    "\n",
    "\n",
    "Xs, ys = resample(X, y, random_state=42)\n",
    "\n",
    "Xs = Xs.iloc[0:n_max,:]\n",
    "ys = ys.iloc[0:n_max]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Number exemple: {y.shape[0]}\\n- training set: \\\n",
    "{y_train.shape[0]}\\n- test set: {y_test.shape[0]}\")\n",
    "print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "print(f\"Number of class: {len(np.unique(y))}\")\n",
    "for c in np.unique(y):\n",
    "    print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and model performance evaluation on full dataset (before clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determination of optimal hyperparameters in 48.0 s\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 256} \n",
      "Accuracy Score of cross valdation 76.12%\n",
      "Random Forest, p=50\n",
      "Model score\n",
      "- Accuracy : 73.2 %\n",
      "- Precision : 73.7 % (Happy # positive class)\n",
      "- Recall : 89.7 %\n",
      "- F1 score : 80.9 %\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "n_estimators_range = [32,64,128,256,512]\n",
    "max_depth_range = [4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32,\n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced'}\n",
    "clf = RandomForestClassifier(**params)\n",
    "\n",
    "grid = GridSearchCV(clf, scoring='accuracy', param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Determination of optimal hyperparameters in {time.time() - startTime:0.1f} s\")\n",
    "print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "Accuracy Score of cross valdation {100*grid.best_score_:0.2f}%\")\n",
    "\n",
    "# Learning on full training set with optimals hyperparameters and score on test set\n",
    "params = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "          'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "          'n_estimators' : grid.best_params_['n_estimators'],\n",
    "          'max_depth' : grid.best_params_['max_depth']}\n",
    "clf = RandomForestClassifier(**params).fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"Random Forest, p={X_train.shape[1]}\")\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "p = precision_score(y_test, y_test_pred)\n",
    "r = recall_score(y_test, y_test_pred)\n",
    "print(f\"Model score\\n- Accuracy : {accuracy*100:0.1f} %\")\n",
    "print(f\"- Precision : {p*100:0.1f} % (Happy # positive class)\")\n",
    "print(f\"- Recall : {r*100:0.1f} %\")\n",
    "print(f\"- F1 score : {f1*100:0.1f} %\")\n",
    "res_full  = {\n",
    "    'f1_score' : f1,\n",
    "    'accuracy' : accuracy,\n",
    "    'precision' : p,\n",
    "    'recall' : r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 19 -revtot7- (0.057628)\n",
      "\tActionable at individual level (2)\n",
      "2. feature 15 -NOT_PROF- (0.045291)\n",
      "\tActionable at individual level (1)\n",
      "3. feature 9 -NOT_AMIS- (0.044856)\n",
      "\tActionable at individual level (1)\n",
      "4. feature 33 -NIVPERSO- (0.037919)\n",
      "\tActionable at individual level (2)\n",
      "5. feature 14 -NOT_LIBR- (0.037460)\n",
      "\tActionable at individual level (1)\n",
      "6. feature 25 -CDV5- (0.035741)\n",
      "\tActionable at individual level (2)\n",
      "7. feature 22 -NBENF6- (0.035219)\n",
      "\tActionable at individual level (2)\n",
      "8. feature 10 -SOUFFDEP_Oui- (0.035098)\n",
      "\tActionable at individual level (2)\n",
      "9. feature 20 -CADVIE- (0.034076)\n",
      "\tActionable at individual level (1)\n",
      "10. feature 49 -ETATSAN- (0.033789)\n",
      "\tActionable at individual level (1)\n",
      "11. feature 28 -INQALIM- (0.033493)\n",
      "\tActionable at individual level (1)\n",
      "12. feature 46 -NOT_FAMI- (0.033475)\n",
      "\tActionable at individual level (1)\n",
      "13. feature 0 -CONFENTR- (0.031363)\n",
      "\tActionable at individual level (1)\n",
      "14. feature 47 -SECURITE- (0.030271)\n",
      "\tActionable at individual level (2)\n",
      "15. feature 21 -INQCHOMA- (0.030152)\n",
      "\tActionable at individual level (1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3X+cHXV97/HX2wSCgAQNUYEEEkv0\nGn8hpmB7/ZFCxYDaiIVr8Bf10lK1XLXWH1iviFRvRXvlasVaNBEaq+ANV7stUdTi4u+QRSIkQHAJ\nwazhx0JCJIQQFj73j+/3ZL+ZnM2e3T3J/pj38/E4jz1n5jszn/nOzGe+5zuzcxQRmJlZPTxptAMw\nM7N9x0nfzKxGnPTNzGrESd/MrEac9M3MasRJ38ysRpz0rdYkfUnSR0c7DrN9Rb5P34ZD0nrgGcDj\nxeBnR8TGEcxzPvC1iJgxsujGJ0mXAT0R8T9HOxabuNzSt5F4XUQcXLyGnfDbQdLk0Vz+SEiaNNox\nWD046VvbSXqppJ9JelDSr3ILvjHu7ZJulfSQpHWS/jIPPwj4DnCEpK35dYSkyyR9oph+vqSe4vN6\nSR+SdBPwsKTJebqrJPVKulPSu/cQ6875N+Yt6YOS7pN0t6TXSzpV0u2SNkn622LaCyQtk3RlXp9f\nSnpRMf65kjpzPayR9CeV5f6TpOWSHgbOBt4MfDCv+7/ncudJuiPP/xZJpxXz+DNJP5H0D5I253U9\npRj/NElflbQxj/92Me61klbl2H4m6YXFuA9J+m1e5lpJJ7Ww2W28iAi//BryC1gP/HGT4UcCDwCn\nkhoVr8qfp+fxrwF+DxDwSmAbcFweN5/UvVHO7zLgE8XnXcrkOFYBM4En52XeAJwP7A88C1gHvHqA\n9dg5/zzvvjztfsBfAL3A14GnAM8DtgPPyuUvAB4DTs/l3w/cmd/vB3QDf5vjOBF4CHhOsdwtwH/N\nMR9QXddc7gzgiFzmjcDDwOF53J/l5f8FMAl4J7CR/m7bq4ErgafmeF6Zhx8H3AeckKc7K9fjFOA5\nwAbgiFx2FvB7o72/+dW+l1v6NhLfzi3FB4tW5FuA5RGxPCKeiIjvA12kkwARcXVE3BHJdcD3gJeP\nMI7PR8SGiHgE+H3SCebCiNgREeuALwOLWpzXY8AnI+Ix4ArgMOBzEfFQRKwB1gAvLMrfEBHLcvnP\nkpL3S/PrYOBTOY5rgf8Aziym/beI+Gmup+3NgomI/xsRG3OZK4FfA8cXRe6KiC9HxOPA5cDhwDMk\nHQ6cArwjIjZHxGO5viGdJP45IlZExOMRcTnwaI75cVLynytpv4hYHxF3tFh3Ng446dtIvD4iDs2v\n1+dhRwNnFCeDB4GXkZIRkk6R9IvcVfIg6WRw2Ajj2FC8P5rURVQu/29JF51b8UBOoACP5L/3FuMf\nISXz3ZYdEU8APaSW+RHAhjys4S7SN6FmcTcl6W1FN8yDwPPZtb7uKZa/Lb89mPTNZ1NEbG4y26OB\nv6nU0UxS674beC/pW8x9kq6QdMRgcdr44aRv7bYBWFqcDA6NiIMi4lOSpgBXAf8APCMiDgWWk7p6\nAJrdSvYwcGDx+ZlNypTTbQDurCz/KRFx6ojXrLmZjTeSngTMIHWxbARm5mENRwG/HSDu3T5LOpr0\nLeVcYFqur9X019eebACeJunQAcZ9slJHB0bENwAi4usR8TLSySGAi1pYno0TTvrWbl8DXifp1ZIm\nSTogXyCdQerbnkLqJ+/LFx1PLqa9F5gmaWoxbBVwar4o+UxSK3RPrgd+ly9GPjnH8HxJv9+2NdzV\nSyS9QenOofeSukl+AawgnbA+KGm/fDH7daQuo4HcS7oG0XAQKen2QroITmrpDyoi7iZdGP+ipKfm\nGF6RR38ZeIekE5QcJOk1kp4i6TmSTswn6O2kbzaPD7AYG4ec9K2tImIDsJDUpdJLalV+AHhSRDwE\nvBv4JrAZeBPQUUx7G/ANYF3udjgCWAr8inSh8XukC5N7Wv7jpOR6LOmi6v3AV4Cpe5puBP6NdIF1\nM/BW4A25/3wH8CekfvX7gS8Cb8vrOJDFpL70ByV9OyJuAf438HPSCeEFwE+HENtbSdcobiNduH0v\nQER0kfr1v5Dj7iZdFIZ0Uv5Ujvke4OmkbWkThP85y2yYJF0AHBMRbxntWMxa5Za+mVmNOOmbmdWI\nu3fMzGrELX0zsxoZcw+oOuyww2LWrFmjHYaZ2bhyww033B8R0wcr11LSl7QA+BzpOR1fiYhPVcZP\nAf4FeAnpOStvjIj1kvYj3S53XF7Wv0TE3+9pWbNmzaKrq6uVsMzMLJN0VyvlBu3eUXrk6yWk+43n\nAmdKmlspdjawOSKOAS6m/z/4zgCmRMQLSCeEv5Q0q5XAzMys/Vrp0z8e6I6IdfkfTq4g/fNNaSHp\nYU8Ay4CTJIn034QH5f9WfDKwA/hdWyI3M7MhayXpH8muD4bqYdeHRu1SJiL6SI+MnUY6ATwM3A38\nBviHiNhUXYCkcyR1Serq7e0d8kqYmVlrWkn6zR7uVL3Pc6Ayx5Oe23EEMJv0ZL9n7VYw4tKImBcR\n86ZPH/Q6hJmZDVMrSb+H4kmC9D9FsGmZ3JUzFdhEerbKd/OzSO4jPTdk3kiDNjOz4Wkl6a8E5kia\nLWl/0o9RdFTKdJB+fQfSrwhdG+m/vn4DnNh4kh/pRxr29MApMzPbiwZN+rmP/lzgGuBW4JsRsUbS\nhcVvfi4mPRK3G3gfcF4efgnpBx1Wk04eX42Im9q8DmZm1qIx9xiGefPmhe/TNzMbGkk3RMSg3efj\n5jEM8+fPZ/78+aMdhpnZuDZukr6ZmY2ck76ZWY046ZuZ1YiTvplZjTjpm5nViJO+mVmNOOmbmdWI\nk76ZWY046ZuZ1YiTvplZjTjpm5nViJO+mVmNOOmbmdWIk76ZWY20lPQlLZC0VlK3pPOajJ8i6co8\nfoWkWXn4myWtKl5PSDq2vatgZmatGjTpS5pE+gWsU4C5wJmS5laKnQ1sjohjgIuBiwAi4l8j4tiI\nOBZ4K7A+Ila1cwXMzKx1rbT0jwe6I2JdROwArgAWVsosBC7P75cBJ0lSpcyZwDdGEqyZmY1MK0n/\nSGBD8bknD2taJv+m7hZgWqXMGxkg6Us6R1KXpK7e3t5W4jYzs2FoJelXW+wA1R/W3WMZSScA2yJi\ndbMFRMSlETEvIuZNnz69hZDMzGw4Wkn6PcDM4vMMYONAZSRNBqYCm4rxi3DXjpnZqGsl6a8E5kia\nLWl/UgLvqJTpAM7K708Hro2IAJD0JOAM0rUAMzMbRZMHKxARfZLOBa4BJgFLImKNpAuBrojoABYD\nSyV1k1r4i4pZvALoiYh17Q/fzMyGYtCkDxARy4HllWHnF++3k1rzzabtBF46/BDNzKxd/B+5ZmY1\n4qRvZlYjTvpmZjXipG9mViNO+mZmNeKkb2ZWI076ZmY14qRvZlYjTvpmZjXipG9mViNO+mZmNeKk\nb2ZWI076ZmY14qRvZlYjTvpmZjXipG9mViMtJX1JCyStldQt6bwm46dIujKPXyFpVjHuhZJ+LmmN\npJslHdC+8M3MbCgGTfqSJgGXAKcAc4EzJc2tFDsb2BwRxwAXAxflaScDXwPeERHPA+YDj7UtejMz\nG5JWWvrHA90RsS4idpB+4HxhpcxC4PL8fhlwkiQBJwM3RcSvACLigYh4vD2hm5nZULWS9I8ENhSf\ne/KwpmUiog/YAkwDng2EpGsk/VLSB5stQNI5krokdfX29g51HczMrEWtJH01GRYtlpkMvAx4c/57\nmqSTdisYcWlEzIuIedOnT28hJDMzG45Wkn4PMLP4PAPYOFCZ3I8/FdiUh18XEfdHxDZgOXDcSIM2\nM7PhaSXprwTmSJotaX9gEdBRKdMBnJXfnw5cGxEBXAO8UNKB+WTwSuCW9oRuZmZDNXmwAhHRJ+lc\nUgKfBCyJiDWSLgS6IqIDWAwsldRNauEvytNulvRZ0okjgOURcXU7V2D+/PkAdHZ2tnO2ZmYT0qBJ\nHyAilpO6Zsph5xfvtwNnDDDt10i3be5zPiGYme2qpaQ/qqTmn6N6LdnMzAbjxzCYmdWIk76ZWY04\n6ZuZ1YiTvplZjTjp72Xz58/feReRmdloc9I3M6sRJ30zsxpx0jczqxEnfTOzGnHSNzOrESd9M7Ma\ncdI3M6sRJ30zsxpx0jczqxEnfTOzGmkp6UtaIGmtpG5J5zUZP0XSlXn8Ckmz8vBZkh6RtCq/vtTe\n8M3MbCgG/REVSZOAS4BXkX7ofKWkjogof+v2bGBzRBwjaRFwEfDGPO6OiDi2zXGbmdkwtNLSPx7o\njoh1EbEDuAJYWCmzELg8v18GnCRVf/LKzMxGWytJ/0hgQ/G5Jw9rWiYi+oAtwLQ8brakGyVdJ+nl\nzRYg6RxJXZK6ent7h7QCw+WnX5pZHbWS9Ju12Ks/UDtQmbuBoyLixcD7gK9LOmS3ghGXRsS8iJg3\nffr0FkIyM7PhaCXp9wAzi88zgI0DlZE0GZgKbIqIRyPiAYCIuAG4A3j2SIOe6PwtxMz2llaS/kpg\njqTZkvYHFgEdlTIdwFn5/enAtRERkqbnC8FIehYwB1jXntDNzGyoBr17JyL6JJ0LXANMApZExBpJ\nFwJdEdEBLAaWSuoGNpFODACvAC6U1Ac8DrwjIjbtjRVpl0YLu7Ozc0Isx8ysNGjSB4iI5cDyyrDz\ni/fbgTOaTHcVcNUIYzQzszbxf+SamdWIk76ZWY046Q+B76oxs/HOSb8NfDIws/HCSd/MrEZauntn\nzCof79N4H9V/FjYzs4bxnfQHUn3Wm08IZmaAu3fGHV8/MLORcNKfIHwyMLNWOOmbmdWIk76ZWY04\n6ZuZ1YiTfg24v9/MGpz0a8wnA7P6cdI3M6uRlpK+pAWS1krqlnRek/FTJF2Zx6+QNKsy/ihJWyW9\nvz1hm5nZcAya9PPPHV4CnALMBc6UNLdS7Gxgc0QcA1wMXFQZfzHwnZGHa/uKu37MJqZWWvrHA90R\nsS4idgBXAAsrZRYCl+f3y4CTpPTsA0mvJ/0u7pr2hGxmZsPVStI/EthQfO7Jw5qWiYg+YAswTdJB\nwIeAj+9pAZLOkdQlqau3t7fV2M3MbIhaSfpqMqz65LKBynwcuDgitu5pARFxaUTMi4h506dPbyEk\nMzMbjlaestkDzCw+zwA2DlCmR9JkYCqwCTgBOF3Sp4FDgSckbY+IL4w4cjMzG7JWkv5KYI6k2cBv\ngUXAmyplOoCzgJ8DpwPXRkQAL28UkHQBsNUJ38xs9Aya9COiT9K5wDXAJGBJRKyRdCHQFREdwGJg\nqaRuUgt/0d4M2szMhqelH1GJiOXA8sqw84v324EzBpnHBcOIz8aYxm2cnZ2dY3J+ZrZn4+aXszrb\nNaNmv6rlX9Qys5oYN0l/n/Bv7prZBOdn75iZ1YiTvplZjTjpm5nViPv0W+GLv2Y2QTjpj5Qv/prZ\nOOKkv7f424GZjUHu07fa828HWJ24pT8a3CVkZqPESX8sadYlBD4hmFnbOOmPFwNdI/CJwsyGwH36\nZmY14qRvZlYj4757p3O0A7Cd/Jhks7Fv3Cf9Pekc7QDMzMaYlrp3JC2QtFZSt6TzmoyfIunKPH6F\npFl5+PGSVuXXrySd1t7wbY+k9LruuvSqXvQ1s9oZNOlLmgRcApwCzAXOlDS3UuxsYHNEHANcDFyU\nh68G5kXEscAC4J/zD6ebmdkoaCUBHw90R8Q6AElXAAuBW4oyC4EL8vtlwBckKSK2FWUOAHwf4Vgx\nQf9BzNcVzPaslaR/JLCh+NwDnDBQmfxD6luAacD9kk4AlgBHA2+NiL7qAiSdA5wDcNRRRw11Hayd\n/MwgswmtlT79Zh3B1SwwYJmIWBERzwN+H/iwpAN2KxhxaUTMi4h506dPbyEkMzMbjlaSfg8ws/g8\nA9g4UJncZz8V2FQWiIhbgYeB5w83WBuf/EAzs7Gjle6dlcAcSbOB3wKLgDdVynQAZwE/B04Hro2I\nyNNsyF0+RwPPAda3K3jbxybodQCzOhk06eeEfS5wDTAJWBIRayRdCHRFRAewGFgqqZvUwl+UJ38Z\ncJ6kx4AngHdFxP17Y0XMzGxwLd0+GRHLgeWVYecX77cDZzSZbimwdIQxmplZm/jZO2ZmNeKkb2ZW\nI/7v2IrO0Q7AdvI/Wpm1n1v6Nu6M9VtAx3p8Vm+1bel3jnYAZmajwC19M7MaqW1Lfzg6RzsAGzZf\nHzBL3NI3M6sRJ30zsxpx904bdI52AGZmLXJL32wM8G2etq+4pW8j1+yHV8BP4DQbg9zSNzOrEbf0\nx5nOIQ634fNtnjYRuaVvto8Mp9/eff3Wbk76ZsPgZLxnrp+xq6WkL2mBpLWSuiWd12T8FElX5vEr\nJM3Kw18l6QZJN+e/J7Y3fDMzG4pBk76kScAlwCnAXOBMSXMrxc4GNkfEMcDFwEV5+P3A6yLiBaTf\n0PWvaJmZjaJWWvrHA90RsS4idgBXAAsrZRYCl+f3y4CTJCkiboyIjXn4GuAASVPaEbi1rhNf6J2I\nfI3AhqOVpH8ksKH43JOHNS0TEX3AFmBapcyfAjdGxKPVBUg6R1KXpK7e3t5WYx/XOnEitrFloBOC\nTxQTSyu3bKrJsOp/3eyxjKTnkbp8Tm62gIi4FLgUYN68ef6PnjGsc7QDsEGN9VtNx3p8E10rSb8H\nmFl8ngFsHKBMj6TJwFRgE4CkGcC3gLdFxB0jjtj2ic52zaj8b13/p67ZqGule2clMEfSbEn7A4uA\njkqZDtKFWoDTgWsjIiQdClwNfDgiftquoM3MbHgGbelHRJ+kc4FrgEnAkohYI+lCoCsiOoDFwFJJ\n3aQW/qI8+bnAMcBHJX00Dzs5Iu5r94pMJJ0TbDlN7el5Pc3G+dvBmNTOrhp3++wbLT2GISKWA8sr\nw84v3m8Hzmgy3SeAT4wwRjOruYFOCD5RDJ2fvWPji68RmI2IH8NgZhOSbzVtzi19mxh8HcCsJU76\nNvG5S8hsJyd9qy//4pfVkPv0zcxqxC19s2bcJWQTlJP+XtY52gFYew33n8p8EhlT6nx/v5O+tU3n\naAcwHvmuI9vHnPTNxqqBvh34RLHX1OEbgJO+2UQylBNFY5zViu/eMTOrEbf0zepuoO4iPwl1FxOl\n68dJ38zay9cixjQnfTMbfb4Wsc+01KcvaYGktZK6JZ3XZPwUSVfm8SskzcrDp0n6oaStkr7Q3tDN\nrNYkuO669JJ2P0FYU4O29CVNAi4BXkX6LdyVkjoi4pai2NnA5og4RtIi0o+gvxHYDnwUeH5+mZnt\nXf52sEettPSPB7ojYl1E7ACuABZWyiwELs/vlwEnSVJEPBwRPyElfzMzG2WtJP0jgQ3F5548rGmZ\niOgDtgDTWg1C0jmSuiR19fb2tjqZmZkNUStJv1lHWfV7UitlBhQRl0bEvIiYN3369FYnMzOzIWrl\n7p0eYGbxeQawcYAyPZImA1OBTW2J0Gqrc7QDsInHt4221NJfCcyRNFvS/sAioKNSpgM4K78/Hbg2\nomY1aftMJz4hmA3XoC39iOiTdC5wDTAJWBIRayRdCHRFRAewGFgqqZvUwl/UmF7SeuAQYH9JrwdO\nrtz5YxNc52gHYGY7tfTPWRGxHFheGXZ+8X47cMYA084aQXxmo6ZztAMw2wv8H7lmw9A52gGYDZOT\nvtVC52gHsBd0DnG4DaImzwxy0jfbRzpHOwDGRgw2upz0zWzYOkc7ABsy/4iKmVmNuKVvZmNC5zDH\njbbx9uMqTvpmY1jnGFjWvoxhohmLJwQnfbMxoHO0A9iHOvfRvNq5nHYbzZOB+/TNzMaQ+fPn7zwp\n7A1u6ZtZ7XSOdgCjyC19M7MacUvfJpTO0Q7AbIxz0jdrs87RDmAM6BztAPaVgR7dMIY56ZuZtaBz\nKIXH8PN6nPTNzPaloTzYrTEua8etnr6Qa2ZWIy0lfUkLJK2V1C3pvCbjp0i6Mo9fIWlWMe7Defha\nSa9uX+hmZjZUg3bvSJoEXAK8ivQD6CsldVR+8vBsYHNEHCNpEXAR8EZJc0k/nfg84AjgB5KeHRGP\nt3tFzMxGqnO0AxhIG68RtNLSPx7ojoh1EbEDuAJYWCmzELg8v18GnCRJefgVEfFoRNwJdOf5mZnZ\nKGjlQu6RwIbicw9wwkBl8g+pbwGm5eG/qEx7ZHUBks4BzgE46qijdh25p7PZQOOGM0275zeWpxkL\nMTSGN/7dvLwwNZZjGO/1vbenGQsx7Ou497T/DDRuONMMNG6IWkn6ajKsWgsDlWllWiLiUuBSgHnz\n5o2N+5rMzFrQ7oem7Wl+7VhWK0m/B5hZfJ4BbBygTI+kycBUYFOL05qZTUgDJenRfNRyK336K4E5\nkmZL2p90YbajUqYDOCu/Px24NiIiD1+U7+6ZDcwBrm9P6GZmNlSDtvRzH/25wDXAJGBJRKyRdCHQ\nFREdwGJgqaRuUgt/UZ52jaRvArcAfcBf+c4dK42lH5cwq4OW/iM3IpYDyyvDzi/ebwfOGGDaTwKf\nHEGMZmbWJv6PXDOzGvGzd6z23MVkdeKWvplZjTjpm5nViJO+mVmNOOmbmdWIk76ZWY046ZuZ1YiT\nvplZjTjpm5nViJO+mVmNKIb5k1t7i6Re4K4BRh8G3D+E4cMdN5anGQsxeF3Hfgx1irtO67qncUdH\nxPQBpukXEePmRXqqZ8vDhztuLE8zFmLwuo79GOoUd53WdbBxrbzcvWNmViNO+mZmNTLekv6lQxw+\n3HFjeZqxEIPXdezHUKe467Sug40b1Ji7kGtmZnvPeGvpm5nZCDjpm5nVyUhu/dmbL2AJcB+wuhj2\nojysD/gdcEgefgHwW2BVfp0KvAdYDawB3g9cD/wqf/54nm4x6Yfc+4AtwMHFsmYC3UAAtwHvKZZ1\nD/AQsJ30PwWNcZ8BHiziOzQPfxrwI2AbsBW4tZjmacD3gV/naa7Jw08Ebs7lH8xxN6Y5FvhFXtdt\nwE/ycJF+j/j2vIx3AwuAtXldziP9uP2NwH/kaX6c5/0Q8FiOobGcM0g/ah95nmXdvTevf6N+Pl7M\nr7EdNgIdzeq+qOdDgWU5xkdyPTQr94+5LmYCP8zrd0uu/+p2nU3/frIF2L9YnzXAE8C8POw5Rbyr\n8vr/daWOvplj257/frrYH2/IcT1Ubtc8/n8U69VdxHZ9nteDeR0acZ+Ul/twnuevi3HK8fXlad+d\nh18JPJC33Q5gVZN9pAs4nuKYAg5otl2Af80xr87zvbqI7ea8nttybOW6DnS8/B1wU1G3369s1y8A\njxd1fW4xn8PysL/OMa7O67uySdyXAXcW2/FYYH2OeRWV2xzpPw5+QyXPFNtuS67v3mL43+Xt/FDe\nRmuLdb2yWP6jwJaiTm/P9bapEveJpHvu+4DNwOQil9yW6+5b+W+jjhbn9b+JdOwcXMY+aG4d7eS+\nh6T/CuA4dk36K/PGOA7oAf6uSMTvL8o9P+8gB5J+EvIHwIvyuP2AFcBLgUOK5dwPnFfM4yXAz0hJ\n5ei80ebmZX0cOC6Xe0ox7mTgj/L8eoGLcplPk5LxcaTEe3ExzafzsPflnaWb9A1sA/Bf8zQXAu8q\npvkecEqephN4IC/n7cC/AE/Kn58J3AE8C9g/7ygXAV9v7EC53OF5OVcB5xTLeS4pKf4YmFepuxfn\nMuvzclYAL61sw6uAtzV2ynL6oszlwJ+TktpTSSeBXcrlZS8lHWSHV+r+1zmOMrZv5u10HOkge2cu\n31ifTnLSb5II7iEd2DvriHQwf6DJ9l4JnJaX899z3TbG/RFpv/tAntf3ihPIIuBg4EvAXxVx355j\nPDhv78uLcW8HvkvaL1cDT29yrNwPnJ+HfQ84Jb8/Na/zzmMq1/du2yWXFWnfWg/cnMvcDrw8T/8u\n4GuNdR3keGk0zN5HOvncVcQ9Lw97rKjrFwOz8rIPA44kJfMnF/X3l03ivgw4vbI915NPHE229fvy\ndvkZu+eZxrY7KY+7tRh3CP3Hy7tJCXhnPRTzvhVYW9S/8nb9RrHN/5B0nL8pz+8+4Ow8zcn0nwD+\nk9Q4aNTRIcWyPkuRt1p5jdnunYj4EemALT2H1DLYREoAfzrA5M8FfhER2yKiD7gOeHUet19+RUT8\nrliOSK2Lhg8D78zDHiZtxCPzuIci4pc5zkYL78iI+F5E/DDPbxswI5dfCHwhT3M5aSdozG8h6QB9\nDfAJUgKdBjwaET/N03wfeG0xTZAOjNcAPyG1/MjxXhgRT+TPs0ktzHURsQNYnuvsK2VlRcTdpOR5\nInBFsT63RsRaUkusWnc3RsQt1eGNeUp6Sp7ftyNia7Nykhon3cWRbI6IB8tykiaRWj0fbMRaqftb\ncp2U8z4x1+UmUuvp9bl8Y30GchLpIPzDSh09Qko8u2xv0v747WIbva4Y9848jwX57w5JyrEty3Vy\neY6tEXeQDuitwFTg3mLcO0mt4AdyHPc1giv24amkpEJjXvn9VGBjeUzl+t5tu0TE8hz/a4CrSd8I\nGvPbkdd1KqmFXB4TTY+XiPidpBl5fjfSv+0nAZ/PddtXrMuNEbG+sl0mA0+WNJnUkLuzGjdDUMTz\nlVwf1TzzTuBTEfGfeVxj/yfnjMY+eBDp29XOeijmPY3U+0BELC/q+3rgqBz346Tj/OtUclrOJX15\nftNJ35p3xpCXJeDJQ13/UW/R7+lFSmzlGfhnpCQ5C7iblHwhterWk77uLAFOIJ19p5F2kp+TThar\ncsVeVMzzq6RW+VbgwDzsT4DPRX9r4cWknfyQJst6YWNcJe7fAW/Jnx+srNeWYn4Pkr6ivQSYT9qJ\nRGoxNbogPkf6qteY5rmkk8o9Ofb/zOUeAD5Caj19h5QkvlIs93pSq3U+RUs/j3tbjmNWk/XpJH2N\nrdbdpBzvLsPL+RXlmtX9sTmmy0gJYXGu153lSN10f53fb22yf/ymnIbUOuwuxt/G7l/dO2ne0l+S\n42hsi0bL6rK8/jflGBvb4WfAwuhv3W0txq0inZAa3Qs/rsQ2ifQ1//FiXV+et2EP6URe1kNj295E\n6lqYU4n9vwGPFJ+fm2PZQEo+R1ePqT1sl2X0H0M/axLbLaRv0411HfB4ycNuJe2rd9L/jec9pG+e\nLyEl/ur+uJ7+7p335Bh7SV1KJwO1AAAHf0lEQVQlu8Vd2UYXA1Py8n5J6oI7p7J+O7cxu+eZVaRv\n8ytIXWR3VGL7ZK7X1aQWermuy0jfXNc2WacppON2G2lf3Xmc5xjuJ3+zqsT6o7zM8tv5V0mNgh+S\n81bLeXW0E/seg9t9Y/wXUqv45rzCjW6NZ+Qd4Um5cpYAZ+cN/iPS1+iLc9lDc0U9v5jvs/IO/XbS\nSWIFMDWPuyvvBG9osqxP5w31hkrcnyEl/cYtsQ8W4w4mtWwa89sKfDG/n09qTQH8ASlRXJ93kG3F\nNB3Ad/P7C8h9jnlef5Pfv4F0sH0lf34t6SvrP9I86X8HeDPpAKmuT2feMZvV3fpcf9Xh3wH+tDKf\nXabP8+wDTsifP0fqWmmUewXpm0zja+7WSj3ujLWY5uXsnvSrB1InlaRP6v7aAny12BaNpH846QB9\nGmk/+UZlf7yBtN+V2/UuUgIS8I68/aY3YstlZpIS/w9JSfT/FXXxAVJXXWPcVuBv6D/R/bgS/9eA\nu4vPn2/UP+mE8INmx1R1u+T95IvAl0kJp1EHZWwfIe/3DH68vJb+/ftS0onkiLze/5SHD5j0SV1+\n1+a62w/4Nv2NqTLuxjaaQvoGdT5wRC73dNIJ5hWVeObTPOmvzvUnUiNzB/lYrsT4MVILfJd1Bf4p\n/62u05eB/1OJu3GcryJ179xYlH8t6aTzLZofs5Pyct4+pLy6txP3SF7NdtBi+O3A9a1MA/wv4F2V\njfX+yjTr8g7wglz56/PrCVIXwTMr89yP1G10d2X4WaSTzZpi2Nq8U+6XN/Z9xbgH8o6zPi/3CeBr\nleV0kS/Q5WHbSS2u9aQWVJAO+tuAWbmMSImicWH470lJbXOeZltjOaRvRA+Quije16ROO+n/1lGt\nu/Wkg3Pn8GJ+BwxwoDTKPRNYX4x7Of0XDj+WX/dUtkV3rpNrqrHm8h8gJaTJebve0aiDZutTDFuY\n94GyXss6aizzEnY/+PYjHbi/KYbdQWqZNub1BCmJ3k//SewP8jwbcd9RTH8UqUX9MdKNCLfl9ZlF\nSkpbirKT87JuK4Ztob/RIeB3gxxTjeU09pPGN8ltpG6eOyr7/T358x6Plzy/Rp3eV4zfSjpJ9pH2\n3+p+v560X51B6v5rDH8bOWk32x/zsPlNttEFxfpVt/G32DXpfxeYX9TXo8D0wY7/Yt6P53Ut95+P\nkU5YT2oWN/3XMb5ZDPv3vOy7qOyPRZlXVtd1sNeY7dNvRtLTG29JZ/4v5eGHF8VOA1Y3yko6irTj\nXJ0/Pxn4Y2CtpGOK6Q4hHTQ3R8TTSf3hPyLtnHMi4p7GsnJf2uI83XVFfAuAD5G+3kUx7w7SyWAx\naWe5rBi3BPh8RMwi7RTrIuItkp6el/NVUkvlfcU0d5JaO7NI3za2RMRb8vQn5jKvJLX050iaTdrJ\n1gMvI11IvDZPQ66fB0knqs8Wy0HSdFJSKevuNknTJR2aix3QGF7M7z8iYntZrpweINfpBknPyct5\nDXBLUe6GiHhmRMzK67oNmJPr8VZgaZN530o6sZ6eY3kq8G8M7kzSjQEz8rJ21lHevxrLfIyUdCm2\n0WLSie6CYn6fIbVkZ5GSzaO5Xn4IvD3HfRbpOksj7qmSTsjjXkVqLDTqq9y2B5EaPQ1/TDrJ9BXD\nNpL2AfJ0vy5Xdg/b5Q5SK3xaow5IJ8Spkp6d13UH8FOAwY4XYElRp98A7o2Ip0bEwRExOSImkxox\ny4v9sfQb4KWSDsx1fSppP67uj4fnYSJdJ1mbrysh6SDShdHVEfHh6jYm3R1UKut6Nulb/f15XnOK\nbf5Eox5yXXyYdOz/hPTtqrH//Dlp335HRDxRibuR0/YnneQaOW0B8HvAjIg4uoj1rY28leN4Hf3H\nXWuGcobYly/SDnI36SDrIXXXvIfUbdJHOps2hi8ldfncREqwh5NaXreQvtb9Oamv9ibSAXt+3pA/\nJSW7x/IG/C39V89fRr54RX+/7Kl5WXfkcVvy/BrjukkXsR7L47fm+KaRWutB6o8t5zeNdHX+16Ru\ngkbL/DOknTtIB3B5O+rLctlf5XX8cZ7mUNLJ7WbSdYwX5fK355g/0qwlRP8FtpsqyzmN1I32RF6n\nh+i/O+RTuW4ij7uhmF8nsCC/f2G17ivb+dhcN7fTf2vqbuVy2a3FdrmJtLNvI50Ed05Df3ddX469\nsZ+clt8/mterUdcH5vJTm7UWc10HKTltystu3Bb8mzzuvkrd7U/69rU6r9vPi9huzjE01rcR92l5\nP3iE/tsBzy+27W/p31fvpX9fXUfaF8tjpdxHVpD6sMtj6l76u6DKuusj7SuNO8nWFrE19vutpP1u\nFXDqIMfLVXn+N5GugfygyXbd2b1DuiOmJ8exkXSx9eN5W68mtX5XNYn72rzc1bnen5/XvXFr50ea\nLHd+rtNqnmlsu0Zu6CvGXZXrO0i5aE2lHi4jdefNL9apj3QNYFte13uLuD9D/62hZU7rztM09qkO\nUk9EI2811vVfKa6/tfLyYxjMzGpkXHXvmJnZyDjpm5nViJO+mVmNOOmbmdWIk76ZWY046ZuZ1YiT\nvplZjfx/R2xUBJkcihAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0dc430b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features_name = np.array(features)\n",
    "#features_name_sorted_rf = features_name[indices]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "max_features = 15\n",
    "\n",
    "for f in range(min(X.shape[1],max_features)):\n",
    "    print(\"%d. feature %d -%s- (%f)\" % (f + 1, indices[f],features_name[indices[f]], importances[indices[f]]))\n",
    "    if features_name[indices[f]] in cdv_actionable_individual_1_features:\n",
    "        print(\"\\tActionable at individual level (1)\")\n",
    "    elif features_name[indices[f]] in cdv_actionable_individual_2_features:\n",
    "        print(\"\\tActionable at individual level (2)\")\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning and model performance evaluation on each clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators_range = [16,32,64,128]\n",
    "max_depth_range = [2,4,8,16,32,64] \n",
    "param_grid = dict(n_estimators=n_estimators_range, max_depth = max_depth_range)\n",
    "params = {'max_features' :'sqrt', \n",
    "          'random_state' : 32, \n",
    "          'min_samples_split' : 2, \n",
    "          'class_weight' : 'balanced'\n",
    "         }\n",
    "scope = ( RFE_LogisticRegression_50_features )  & set(dataset.columns)\n",
    "features = df.loc[:,scope].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "\n",
      "Analysis cluster method clust3\n",
      "liste of clusters : [2 4 6 1 3 5]\n",
      "cluster 2 : 3053 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "cross validation score 80.75%\n",
      "\n",
      "cluster 4 : 2359 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "cross validation score 84.06%\n",
      "\n",
      "cluster 6 : 2313 elements\n",
      "Number exemple: 2000\n",
      "        - training set: 1600\n",
      "        - test set: 400\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 32, 'n_estimators': 32} \n",
      "cross validation score 82.75%\n",
      "\n",
      "cluster 1 : 528 elements\n",
      "Number exemple: 505\n",
      "        - training set: 404\n",
      "        - test set: 101\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 64} \n",
      "cross validation score 82.67%\n",
      "\n",
      "cluster 3 : 1384 elements\n",
      "Number exemple: 1367\n",
      "        - training set: 1093\n",
      "        - test set: 274\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 128} \n",
      "cross validation score 86.18%\n",
      "\n",
      "cluster 5 : 1494 elements\n",
      "Number exemple: 1472\n",
      "        - training set: 1177\n",
      "        - test set: 295\n",
      "Number of features: p=50\n",
      "Number of class: 2\n",
      "class 0 : 35.0%\n",
      "class 1 : 65.0%\n",
      "Optimal values are {'max_depth': 16, 'n_estimators': 32} \n",
      "cross validation score 83.86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_clustering_methods = []\n",
    "clustering_methods = clustTest1.columns[2:3]\n",
    "\n",
    "for method in clustering_methods:\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"\\nAnalysis cluster method {method}\")\n",
    "    cluster_list = clustTest1[method].unique()\n",
    "    print(f\"liste of clusters : {cluster_list}\")\n",
    "    score_cluster = []\n",
    "    for cluster in cluster_list:\n",
    "        index_scope = clustTest1.loc[clustTest1[method]==cluster,:].index\n",
    "        print(f\"cluster {cluster} : {len(index_scope)} elements\")\n",
    "        \n",
    "        Xc = X.loc[index_scope.intersection(X.index),:]\n",
    "        yc = y[index_scope.intersection(X.index)]\n",
    "        \n",
    "        Xs, ys = resample(Xc, yc, random_state=42)\n",
    "        \n",
    "        Xs = Xs.iloc[0:n_max,:]\n",
    "        ys = ys.iloc[0:n_max]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(Xs, ys,\n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=42)\n",
    "\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "                \n",
    "        print(f\"Number exemple: {ys.shape[0]}\\n\\\n",
    "        - training set: {y_train.shape[0]}\\n\\\n",
    "        - test set: {y_test.shape[0]}\")\n",
    "        print(f\"Number of features: p={X_train.shape[1]}\")\n",
    "        print(f\"Number of class: {len(np.unique(y))}\")\n",
    "        for c in np.unique(y):\n",
    "            print(f\"class {c:0.0f} : {100*np.sum(y==c)/len(y):0.1f}%\")\n",
    "            \n",
    "            \n",
    "        startTime = time.time()\n",
    "        clf = RandomForestClassifier(**params)\n",
    "        grid = GridSearchCV(clf, \n",
    "                            scoring='accuracy', \n",
    "                            param_grid=param_grid)\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        print(f\"Optimal values are {grid.best_params_} \\n\\\n",
    "cross validation score {100*grid.best_score_:0.2f}%\")\n",
    "        print()\n",
    "\n",
    "        # Learning on full training set with optimals hyperparameters and score on test set\n",
    "        params_opt = {'max_features' :'sqrt', 'random_state' : 32, \n",
    "                      'min_samples_split' : 2, 'class_weight' : 'balanced',\n",
    "                      'n_estimators' : grid.best_params_['n_estimators'],\n",
    "                      'max_depth' : grid.best_params_['max_depth']}\n",
    "        clf = RandomForestClassifier(**params_opt).fit(X_train, y_train)\n",
    "\n",
    "            \n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        f1 = f1_score(y_test, y_test_pred)\n",
    "        p = precision_score(y_test, y_test_pred)\n",
    "        r = recall_score(y_test, y_test_pred)            \n",
    "\n",
    "        res  = {'f1_score' : f1,\n",
    "                'accuracy' : accuracy,\n",
    "                'precision' : p,\n",
    "                'recall' : r}\n",
    "            \n",
    "        cl = {'cluster' : cluster,\n",
    "              'size' : len(index_scope),\n",
    "              'model' : 'RandomForestClassifier',\n",
    "              'params' : params_opt,\n",
    "              'metrics' : res\n",
    "             }\n",
    "         \n",
    "        score_cluster.append(cl)\n",
    "        \n",
    "    d = {'clustering_method' : method,\n",
    "         'cluster_scores' : score_cluster\n",
    "        }\n",
    "    score_clustering_methods.append(d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance gain obtained using clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method clust3:\n",
      "cluster 2 (3053), f1 macro 88.8%\n",
      "cluster 4 (2359), f1 macro 92.9%\n",
      "cluster 6 (2313), f1 macro 93.0%\n",
      "cluster 1 (528), f1 macro 89.1%\n",
      "cluster 3 (1384), f1 macro 92.3%\n",
      "cluster 5 (1494), f1 macro 87.7%\n",
      "average f1 on clusters 90.8% gain 9.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    total_size = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']} ({score_cluster['size']}), f1 macro {100*score_cluster['metrics']['f1_score']:0.1f}%\")  \n",
    "        average_score += score_cluster['metrics']['f1_score']*score_cluster['size']\n",
    "        total_size += score_cluster['size']\n",
    "        \n",
    "    average_score = average_score / total_size\n",
    "    print(f\"average f1 on clusters {100*average_score:0.1f}% gain {100*(average_score-res_full['f1_score']):0.1f}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method clust3:\n",
      "cluster 2 (3053) , accuracy 84.2%\n",
      "cluster 4 (2359) , accuracy 89.5%\n",
      "cluster 6 (2313) , accuracy 89.8%\n",
      "cluster 1 (528) , accuracy 90.1%\n",
      "cluster 3 (1384) , accuracy 88.7%\n",
      "cluster 5 (1494) , accuracy 85.4%\n",
      "average accuracy on clusters 87.5% gain 14.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "for score_method in score_clustering_methods:\n",
    "    print(f\"method {score_method['clustering_method']}:\")\n",
    "    average_score = 0\n",
    "    total_size = 0\n",
    "    for i, score_cluster in enumerate(score_method['cluster_scores']):\n",
    "        print(f\"cluster {score_cluster['cluster']} ({score_cluster['size']}) , accuracy {100*score_cluster['metrics']['accuracy']:0.1f}%\")  \n",
    "        average_score = average_score + score_cluster['metrics']['accuracy']*score_cluster['size']\n",
    "        total_size += score_cluster['size']\n",
    "    average_score = average_score / total_size\n",
    "    print(f\"average accuracy on clusters {100*average_score:0.1f}% gain {100*(average_score-res_full['accuracy']):0.1f}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature importance of the models & actionable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
